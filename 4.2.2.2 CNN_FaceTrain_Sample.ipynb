{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"; # for GPU 1.\n",
    "\n",
    "import pathlib\n",
    "# import warnings\n",
    "import random\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "pixel = 128\n",
    "batch_size = 128\n",
    "epoch_size = 100\n",
    "\n",
    "datatype = 'data-face'\n",
    "modelname = 'model/face_cnn_sample_b'+str(batch_size)+'_e'+str(epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(target_size=(128, 128)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3),\n",
    "                     input_shape=(target_size[0], target_size[1], 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    #\n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    ## leeseng: deeper block that make model training converges.\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    #\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # model.add(Conv2D(512, (3, 3)))\n",
    "    # model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001),\n",
    "                                     loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrSchedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 160:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 140:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "\n",
    "    print('Learning rate:', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 124, 124, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 124, 124, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 60, 60, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 6,355,011\n",
      "Trainable params: 6,355,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "model summary: None\n",
      "Found 3738 validated image filenames belonging to 3 classes.\n",
      "Found 1051 validated image filenames belonging to 3 classes.\n",
      "      Unnamed: 0                                           filename    label\n",
      "0              1             data-face/XiaoYan/IMG_4749.MOV-482.jpg  XiaoYan\n",
      "1              2             data-face/XiaoYan/IMG_4705.MOV-732.jpg  XiaoYan\n",
      "2              4  data-face/LeeSeng/VID_20190908_145635.mp4-1233...  LeeSeng\n",
      "3              5  data-face/LeeSeng/VID_20190908_145635.mp4-1399...  LeeSeng\n",
      "4             10      data-face/GabyNg/20190902_124535.mp4-1265.jpg   GabyNg\n",
      "...          ...                                                ...      ...\n",
      "3733        5343            data-face/XiaoYan/IMG_4749.MOV-1701.jpg  XiaoYan\n",
      "3734        5344             data-face/XiaoYan/IMG_4749.MOV-179.jpg  XiaoYan\n",
      "3735        5345             data-face/XiaoYan/IMG_4749.MOV-916.jpg  XiaoYan\n",
      "3736        5347             data-face/XiaoYan/IMG_4747.MOV-251.jpg  XiaoYan\n",
      "3737        5348      data-face/GabyNg/20190902_124535.mp4-1459.jpg   GabyNg\n",
      "\n",
      "[3738 rows x 3 columns]\n",
      "      Unnamed: 0                                           filename    label\n",
      "0              0  data-face/LeeSeng/VID_20190908_145635.mp4-607.jpg  LeeSeng\n",
      "1              3            data-face/XiaoYan/IMG_4749.MOV-2097.jpg  XiaoYan\n",
      "2              6             data-face/XiaoYan/IMG_4747.MOV-296.jpg  XiaoYan\n",
      "3              7            data-face/XiaoYan/IMG_4749.MOV-1992.jpg  XiaoYan\n",
      "4              8       data-face/GabyNg/20190902_124535.mp4-955.jpg   GabyNg\n",
      "...          ...                                                ...      ...\n",
      "1046        5325  data-face/LeeSeng/VID_20190902_091449.mp4-969.jpg  LeeSeng\n",
      "1047        5329  data-face/LeeSeng/VID_20190908_145635.mp4-222.jpg  LeeSeng\n",
      "1048        5334             data-face/XiaoYan/IMG_4749.MOV-537.jpg  XiaoYan\n",
      "1049        5336            data-face/XiaoYan/IMG_4749.MOV-1348.jpg  XiaoYan\n",
      "1050        5346            data-face/XiaoYan/IMG_4747.MOV-1002.jpg  XiaoYan\n",
      "\n",
      "[1051 rows x 3 columns]\n",
      "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator object at 0x7f131b2402b0>\n",
      "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator object at 0x7f131b240470>\n",
      "Learning rate: 0.001\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 1.1206 - acc: 0.3864 - val_loss: 1.0446 - val_acc: 0.3926\n",
      "Learning rate: 0.001\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 9s 319ms/step - loss: 0.6750 - acc: 0.6640 - val_loss: 0.4065 - val_acc: 0.8398\n",
      "Learning rate: 0.001\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 9s 323ms/step - loss: 0.2741 - acc: 0.8859 - val_loss: 0.0273 - val_acc: 0.9951\n",
      "Learning rate: 0.001\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 9s 328ms/step - loss: 0.1627 - acc: 0.9471 - val_loss: 0.0216 - val_acc: 0.9961\n",
      "Learning rate: 0.001\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 9s 323ms/step - loss: 0.0375 - acc: 0.9867 - val_loss: 0.0200 - val_acc: 0.9951\n",
      "Learning rate: 0.001\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 10s 340ms/step - loss: 0.0513 - acc: 0.9853 - val_loss: 0.0112 - val_acc: 0.9980\n",
      "Learning rate: 0.001\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 10s 337ms/step - loss: 0.0290 - acc: 0.9895 - val_loss: 0.0066 - val_acc: 0.9980\n",
      "Learning rate: 0.001\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 0.0106 - acc: 0.9977 - val_loss: 0.0066 - val_acc: 0.9990\n",
      "Learning rate: 0.001\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 10s 353ms/step - loss: 0.0069 - acc: 0.9968 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 10s 351ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 1.8736e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 10s 358ms/step - loss: 0.0032 - acc: 0.9989 - val_loss: 7.3297e-04 - val_acc: 0.9990\n",
      "Learning rate: 0.001\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 10s 357ms/step - loss: 0.0082 - acc: 0.9975 - val_loss: 0.0051 - val_acc: 0.9980\n",
      "Learning rate: 0.001\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 10s 362ms/step - loss: 0.0051 - acc: 0.9992 - val_loss: 1.4886e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 10s 352ms/step - loss: 0.0031 - acc: 0.9986 - val_loss: 1.7867e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 10s 358ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 1.9446e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 11s 363ms/step - loss: 0.0017 - acc: 0.9992 - val_loss: 8.9024e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 11s 362ms/step - loss: 0.0145 - acc: 0.9947 - val_loss: 5.0707e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 10s 344ms/step - loss: 0.0025 - acc: 0.9989 - val_loss: 9.6084e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 10s 356ms/step - loss: 0.0033 - acc: 0.9987 - val_loss: 1.5387e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 10s 350ms/step - loss: 0.0056 - acc: 0.9986 - val_loss: 0.0030 - val_acc: 0.9990\n",
      "Learning rate: 0.001\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 11s 363ms/step - loss: 0.0293 - acc: 0.9919 - val_loss: 0.0048 - val_acc: 0.9980\n",
      "Learning rate: 0.001\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 10s 351ms/step - loss: 0.0116 - acc: 0.9964 - val_loss: 0.0041 - val_acc: 0.9980\n",
      "Learning rate: 0.001\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 10s 351ms/step - loss: 0.3232 - acc: 0.8928 - val_loss: 0.0063 - val_acc: 0.9990\n",
      "Learning rate: 0.001\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 10s 350ms/step - loss: 0.0435 - acc: 0.9842 - val_loss: 4.9920e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 10s 349ms/step - loss: 0.0316 - acc: 0.9884 - val_loss: 6.8841e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.0183 - acc: 0.9953 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Learning rate: 0.001\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 10s 340ms/step - loss: 0.0087 - acc: 0.9972 - val_loss: 3.9801e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 10s 338ms/step - loss: 0.0031 - acc: 0.9989 - val_loss: 6.5268e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 10s 347ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 1.9362e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 10s 329ms/step - loss: 0.0025 - acc: 0.9989 - val_loss: 9.6608e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.0034 - acc: 0.9994 - val_loss: 3.2802e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.0032 - acc: 0.9989 - val_loss: 1.8915e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 9s 321ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 3.8793e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 9s 318ms/step - loss: 0.0038 - acc: 0.9986 - val_loss: 1.6711e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 9s 327ms/step - loss: 0.0014 - acc: 0.9994 - val_loss: 4.6276e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 10s 334ms/step - loss: 0.0036 - acc: 0.9986 - val_loss: 5.3483e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 10s 336ms/step - loss: 0.0026 - acc: 0.9992 - val_loss: 3.8718e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 10s 343ms/step - loss: 0.0020 - acc: 0.9989 - val_loss: 2.0479e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 10s 351ms/step - loss: 0.0031 - acc: 0.9986 - val_loss: 2.4349e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 10s 359ms/step - loss: 7.7594e-04 - acc: 0.9997 - val_loss: 6.0333e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 10s 357ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 5.7704e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 10s 354ms/step - loss: 0.0097 - acc: 0.9972 - val_loss: 1.4743e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 10s 353ms/step - loss: 0.0151 - acc: 0.9958 - val_loss: 9.6967e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 10s 353ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 2.6374e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 10s 358ms/step - loss: 0.0270 - acc: 0.9945 - val_loss: 1.3898e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 10s 358ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 2.5164e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 10s 349ms/step - loss: 6.9236e-04 - acc: 0.9997 - val_loss: 2.7074e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 10s 350ms/step - loss: 3.4251e-04 - acc: 0.9997 - val_loss: 3.6891e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 10s 349ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0051 - val_acc: 0.9980\n",
      "Learning rate: 0.001\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 10s 353ms/step - loss: 0.0013 - acc: 0.9994 - val_loss: 1.2192e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 10s 360ms/step - loss: 0.0138 - acc: 0.9962 - val_loss: 1.1724e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.0151 - acc: 0.9954 - val_loss: 2.9549e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 10s 354ms/step - loss: 0.0156 - acc: 0.9952 - val_loss: 0.0022 - val_acc: 0.9990\n",
      "Learning rate: 0.001\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 10s 348ms/step - loss: 0.0105 - acc: 0.9975 - val_loss: 5.9810e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 10s 355ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 3.1484e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 10s 354ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 1.6651e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 10s 340ms/step - loss: 0.0011 - acc: 0.9994 - val_loss: 2.4678e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 10s 350ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 6.5341e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 10s 342ms/step - loss: 0.0074 - acc: 0.9981 - val_loss: 3.2649e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 9s 327ms/step - loss: 0.0024 - acc: 0.9989 - val_loss: 3.9805e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 5.3772e-04 - acc: 0.9997 - val_loss: 1.7134e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.0010 - acc: 0.9997 - val_loss: 6.5502e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 9s 317ms/step - loss: 1.5282e-04 - acc: 1.0000 - val_loss: 1.5019e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 9s 319ms/step - loss: 2.3395e-04 - acc: 1.0000 - val_loss: 1.3384e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 10s 328ms/step - loss: 5.0529e-05 - acc: 1.0000 - val_loss: 4.1769e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 10s 328ms/step - loss: 6.3471e-05 - acc: 1.0000 - val_loss: 4.5040e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 10s 338ms/step - loss: 1.8884e-05 - acc: 1.0000 - val_loss: 5.8357e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 10s 340ms/step - loss: 3.8736e-05 - acc: 1.0000 - val_loss: 3.5134e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 10s 352ms/step - loss: 3.6331e-05 - acc: 1.0000 - val_loss: 3.2386e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 10s 357ms/step - loss: 4.0327e-05 - acc: 1.0000 - val_loss: 2.2968e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 10s 359ms/step - loss: 1.1758e-04 - acc: 1.0000 - val_loss: 1.9907e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 10s 348ms/step - loss: 3.2933e-05 - acc: 1.0000 - val_loss: 3.3853e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 10s 352ms/step - loss: 1.7242e-05 - acc: 1.0000 - val_loss: 2.0512e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 10s 357ms/step - loss: 2.0058e-05 - acc: 1.0000 - val_loss: 1.6740e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 10s 350ms/step - loss: 7.9254e-04 - acc: 0.9997 - val_loss: 4.3989e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 10s 350ms/step - loss: 0.0028 - acc: 0.9994 - val_loss: 2.0445e-05 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 10s 359ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 3.7088e-04 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 10s 350ms/step - loss: 8.7394e-04 - acc: 1.0000 - val_loss: 3.1644e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 10s 353ms/step - loss: 9.7050e-04 - acc: 0.9997 - val_loss: 4.9533e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 10s 347ms/step - loss: 0.0010 - acc: 0.9994 - val_loss: 1.7287e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 10s 359ms/step - loss: 3.0474e-04 - acc: 0.9997 - val_loss: 2.8948e-06 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 10s 348ms/step - loss: 7.0675e-04 - acc: 0.9994 - val_loss: 2.1583e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 10s 343ms/step - loss: 9.1686e-05 - acc: 1.0000 - val_loss: 2.3353e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 10s 352ms/step - loss: 1.2017e-04 - acc: 1.0000 - val_loss: 1.4226e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 10s 348ms/step - loss: 1.3634e-05 - acc: 1.0000 - val_loss: 1.4377e-07 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 10s 352ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 2.2585e-08 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 10s 347ms/step - loss: 2.8207e-04 - acc: 0.9997 - val_loss: 9.6741e-08 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 10s 348ms/step - loss: 4.9015e-05 - acc: 1.0000 - val_loss: 5.6461e-08 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 10s 343ms/step - loss: 7.8097e-05 - acc: 1.0000 - val_loss: 6.1001e-08 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 9s 318ms/step - loss: 1.9797e-05 - acc: 1.0000 - val_loss: 5.6461e-08 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 2.9871e-05 - acc: 1.0000 - val_loss: 5.1688e-08 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 9s 321ms/step - loss: 8.8061e-06 - acc: 1.0000 - val_loss: 4.8778e-08 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 3.4274e-05 - acc: 1.0000 - val_loss: 3.6787e-08 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 9s 323ms/step - loss: 1.4147e-05 - acc: 1.0000 - val_loss: 4.2957e-08 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 9s 325ms/step - loss: 1.9740e-05 - acc: 1.0000 - val_loss: 3.6554e-08 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 10s 330ms/step - loss: 8.0168e-05 - acc: 1.0000 - val_loss: 2.8289e-08 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 10s 337ms/step - loss: 8.7322e-05 - acc: 1.0000 - val_loss: 2.3283e-08 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 10s 342ms/step - loss: 6.8242e-06 - acc: 1.0000 - val_loss: 2.7590e-08 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 10s 349ms/step - loss: 5.4118e-05 - acc: 1.0000 - val_loss: 3.0617e-08 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 10s 352ms/step - loss: 3.7778e-04 - acc: 0.9997 - val_loss: 8.2655e-09 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "    target_size = (pixel, pixel)\n",
    "    seed = 29\n",
    "\n",
    "    tdf = pd.read_csv(datatype+'_train_set.csv')\n",
    "    vdf = pd.read_csv(datatype+'_v_set.csv')\n",
    "    model = createModel(target_size)\n",
    "\n",
    "    print('model summary:', model.summary())\n",
    "\n",
    "\n",
    "    filepath = modelname + \".hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath,\n",
    "                                 monitor='val_acc',\n",
    "                                 verbose=0,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='max')\n",
    "\n",
    "    # Log the epoch detail into csv\n",
    "    csv_logger = CSVLogger(modelname + '.csv')\n",
    "    # callbacks_list  = [checkpoint,csv_logger]\n",
    "\n",
    "    LRScheduler = LearningRateScheduler(lrSchedule)\n",
    "    callbacks_list = [checkpoint, csv_logger, LRScheduler]\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        samplewise_center=True,\n",
    "        samplewise_std_normalization=True,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.10,\n",
    "        shear_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    vdatagen = ImageDataGenerator(\n",
    "        samplewise_center=True,\n",
    "        samplewise_std_normalization=True,\n",
    "        width_shift_range=0,\n",
    "        height_shift_range=0,\n",
    "        rotation_range=0,\n",
    "        zoom_range=0,\n",
    "        shear_range=0,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    train_generator = datagen.flow_from_dataframe(dataframe=tdf, x_col=\"filename\", y_col=\"label\",\n",
    "                                                  class_mode=\"categorical\", target_size=target_size,\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=batch_size)\n",
    "\n",
    "    valid_generator = vdatagen.flow_from_dataframe(dataframe=vdf, x_col=\"filename\", y_col=\"label\",\n",
    "                                                   class_mode=\"categorical\", target_size=target_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   batch_size=batch_size)\n",
    "    print(tdf)\n",
    "    print(vdf)\n",
    "    print(train_generator)\n",
    "    print(valid_generator)\n",
    "    STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "    STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "\n",
    "    history = model.fit_generator(generator=train_generator,\n",
    "                        validation_data=valid_generator,\n",
    "                        epochs=epoch_size,\n",
    "                        verbose=1,\n",
    "                        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                        validation_steps=STEP_SIZE_VALID,\n",
    "                        callbacks=callbacks_list,\n",
    "                        workers=5,\n",
    "                        use_multiprocessing=True)\n",
    "    # ......................................................................\n",
    "\n",
    "    # Now the training is complete, we get\n",
    "    # another object to load the weights\n",
    "    # compile it, so that we can do\n",
    "    # final evaluation on it\n",
    "    # modelGo.load_weights(filepath)\n",
    "    # modelGo.compile(loss='categorical_crossentropy',\n",
    "    #                 optimizer=optimizers.Adam(lr=0.001),\n",
    "    #                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(modelname+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
