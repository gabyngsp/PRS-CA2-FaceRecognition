{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 16 13:26:00 2019\n",
    "\n",
    "@author: tealeeseng\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; # for GPU 1.\n",
    "import pathlib\n",
    "# import warnings\n",
    "import random\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "pixel = 128\n",
    "batch_size = 128\n",
    "epoch_size = 100\n",
    "\n",
    "datatype = 'data-face'\n",
    "modelname = 'model/face_resnet_rescale_b'+str(batch_size)+'_e'+str(epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resLyr(inputs,\n",
    "           numFilters=16,\n",
    "           kernelSize=3,\n",
    "           strides=1,\n",
    "           activation='relu',\n",
    "           batchNorm=True,\n",
    "           convFirst=True,\n",
    "           lyrName=None):\n",
    "    convLyr = Conv2D(numFilters,\n",
    "                     kernel_size=kernelSize,\n",
    "                     strides=strides,\n",
    "                     padding='same',\n",
    "                     kernel_initializer='he_normal',\n",
    "                     kernel_regularizer=l2(1e-4),\n",
    "                     name=lyrName + '_conv' if lyrName else None)\n",
    "\n",
    "    x = inputs\n",
    "    if convFirst:\n",
    "        x = convLyr(x)\n",
    "        if batchNorm:\n",
    "            x = BatchNormalization(name=lyrName + '_bn' if lyrName else None)(x)\n",
    "\n",
    "        if activation is not None:\n",
    "            x = Activation(activation, name=lyrName + '_' + activation if lyrName else None)(x)\n",
    "    else:\n",
    "        if batchNorm:\n",
    "            x = BatchNormalization(name=lyrName + '_bn' if lyrName else None)(x)\n",
    "\n",
    "        if activation is not None:\n",
    "            x = Activation(activation, name=lyrName + '_' + activation if lyrName else None)(x)\n",
    "        x = convLyr(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resBlkV1(inputs,\n",
    "             numFilters=16,\n",
    "             numBlocks=4,\n",
    "             downSampleOnFirst=True,\n",
    "             names=None):\n",
    "    x = inputs\n",
    "    for run in range(0, numBlocks):\n",
    "        strides = 1\n",
    "        blkStr = str(run + 1)\n",
    "        if downSampleOnFirst and run == 0:\n",
    "            strides = 2\n",
    "\n",
    "        y = resLyr(inputs=x,\n",
    "                   numFilters=numFilters,\n",
    "                   strides=strides,\n",
    "                   lyrName=names + '_Blk' + blkStr + '_Res1' if names else None)\n",
    "        y = resLyr(inputs=y,\n",
    "                   numFilters=numFilters,\n",
    "                   activation=None,\n",
    "                   lyrName=names + '_Blk' + blkStr + '_Res2' if names else None)\n",
    "\n",
    "        if downSampleOnFirst and run == 0:\n",
    "            x = resLyr(inputs=x,\n",
    "                       numFilters=numFilters,\n",
    "                       kernelSize=1,\n",
    "                       strides=strides,\n",
    "                       activation=None,\n",
    "                       batchNorm=False,\n",
    "                       lyrName=names + '_Blk' + blkStr + '_lin' if names else None)\n",
    "\n",
    "        x = add([x, y],\n",
    "                name=names + '_Blk' + blkStr + '_add' if names else None)\n",
    "\n",
    "        x = Activation('relu', name=names + '_Blk' + blkStr + '_relu' if names else None)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createResNetV1(inputShape=(128, 128, 3),\n",
    "                   numberClasses=3):\n",
    "    inputs = Input(shape=inputShape)\n",
    "    v = resLyr(inputs, numFilters=16, kernelSize=5, lyrName='Inpt')\n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=16,\n",
    "                 numBlocks=5,\n",
    "                 downSampleOnFirst=False,\n",
    "                 names='Stg1')\n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=32,\n",
    "                 numBlocks=5,\n",
    "                 downSampleOnFirst=True,\n",
    "                 names='Stg2')\n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=64,\n",
    "                 numBlocks=5,\n",
    "                 downSampleOnFirst=True,\n",
    "                 names='Stg3')\n",
    "#     v = resBlkV1(inputs=v,\n",
    "#                  numFilters=512,\n",
    "#                  numBlocks=6,\n",
    "#                  downSampleOnFirst=True,\n",
    "#                  names='Stg4')\n",
    "    v = AveragePooling2D(pool_size=8,\n",
    "                         name='AvgPool')(v)\n",
    "    v = Flatten()(v)\n",
    "    outputs = Dense(numberClasses,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(v)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.Adam(lr=0.002),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "    # parallel = multi_gpu_model(model, gpus=2)\n",
    "    #\n",
    "    # parallel.compile(loss='categorical_crossentropy',\n",
    "    #          optimizer = optimizers.Adam(lr=0.001),\n",
    "    #          metrics=['accuracy'])\n",
    "    #\n",
    "    # return parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(target_size=(128, 128)):\n",
    "    model = createResNetV1(inputShape=(target_size[0], target_size[1], 3))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the models\n",
    "def printSample(all_image_paths):\n",
    "    img_path = all_image_paths[0]\n",
    "    image_path = img_path\n",
    "    img_raw = tf.io.read_file(img_path)\n",
    "    # print(repr(img_raw)[:100]+' ...')\n",
    "    img_tensor = tf.image.decode_png(img_raw, channels=3)\n",
    "    img_tensor = tf.image.resize_image_with_crop_or_pad(img_tensor, 128, 128)\n",
    "    print(img_tensor.shape, ' ', img_tensor.dtype)\n",
    "    # for n in range(3):\n",
    "    #     image_path = random.choice(all_image_paths)\n",
    "    img = mpimg.imread(image_path)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n",
    "    # display.display(display.Image(image_path))\n",
    "    # print(caption_image(image_path))\n",
    "    # print(matplotlib.get_backend())\n",
    "    img_final = tf.image.resize(img_tensor, [128, 128])\n",
    "    img_final = tf.cast(img_final, tf.float32)\n",
    "    img_final = img_final / 255.0\n",
    "    print(img_final.shape, ' ', img_final.numpy().min(), ' ', img_final.numpy().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrSchedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 160:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 140:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "\n",
    "    print('Learning rate:', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (pixel, pixel)\n",
    "seed = 29\n",
    "\n",
    "\n",
    "tdf = pd.read_csv(datatype+\"_train_set.csv\")\n",
    "vdf = pd.read_csv(datatype+\"_v_set.csv\")\n",
    "\n",
    "# import cv2\n",
    "# # img = cv2.imread('./data-face/XiaoYan/IMG_4749.MOV-482.jpg')\n",
    "# # print(img)\n",
    "\n",
    "# x_train = []\n",
    "# for i in range(len(tdf.index)):\n",
    "#     imgfile = \"./\"+tdf.iloc[i]['filename']\n",
    "#     img = cv2.imread(imgfile)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     x_train.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_conv (Conv2D)              (None, 128, 128, 16) 1216        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_bn (BatchNormalization)    (None, 128, 128, 16) 64          Inpt_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_relu (Activation)          (None, 128, 128, 16) 0           Inpt_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Inpt_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_add (Add)             (None, 128, 128, 16) 0           Inpt_relu[0][0]                  \n",
      "                                                                 Stg1_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_add (Add)             (None, 128, 128, 16) 0           Stg1_Blk1_relu[0][0]             \n",
      "                                                                 Stg1_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_add (Add)             (None, 128, 128, 16) 0           Stg1_Blk2_relu[0][0]             \n",
      "                                                                 Stg1_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk4_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk4_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk4_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk4_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_add (Add)             (None, 128, 128, 16) 0           Stg1_Blk3_relu[0][0]             \n",
      "                                                                 Stg1_Blk4_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk4_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk5_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk5_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk5_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk5_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_add (Add)             (None, 128, 128, 16) 0           Stg1_Blk4_relu[0][0]             \n",
      "                                                                 Stg1_Blk5_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk5_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_conv (Conv2D)    (None, 64, 64, 32)   4640        Stg1_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_lin_conv (Conv2D)     (None, 64, 64, 32)   544         Stg1_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg2_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk1_relu[0][0]             \n",
      "                                                                 Stg2_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk2_relu[0][0]             \n",
      "                                                                 Stg2_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk4_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk4_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk4_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk4_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk3_relu[0][0]             \n",
      "                                                                 Stg2_Blk4_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk4_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk5_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk5_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk5_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk5_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk4_relu[0][0]             \n",
      "                                                                 Stg2_Blk5_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk5_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_conv (Conv2D)    (None, 32, 32, 64)   18496       Stg2_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_lin_conv (Conv2D)     (None, 32, 32, 64)   2112        Stg2_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg3_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk1_relu[0][0]             \n",
      "                                                                 Stg3_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk2_relu[0][0]             \n",
      "                                                                 Stg3_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk4_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk4_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk4_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk4_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk3_relu[0][0]             \n",
      "                                                                 Stg3_Blk4_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk4_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk5_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk5_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk5_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk5_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk4_relu[0][0]             \n",
      "                                                                 Stg3_Blk5_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk5_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "AvgPool (AveragePooling2D)      (None, 4, 4, 64)     0           Stg3_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           AvgPool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            3075        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 473,411\n",
      "Trainable params: 471,139\n",
      "Non-trainable params: 2,272\n",
      "__________________________________________________________________________________________________\n",
      "model summary: None\n",
      "Found 3738 validated image filenames belonging to 3 classes.\n",
      "Found 1051 validated image filenames belonging to 3 classes.\n",
      "      Unnamed: 0                                           filename    label\n",
      "0              1             data-face/XiaoYan/IMG_4749.MOV-482.jpg  XiaoYan\n",
      "1              2             data-face/XiaoYan/IMG_4705.MOV-732.jpg  XiaoYan\n",
      "2              4  data-face/LeeSeng/VID_20190908_145635.mp4-1233...  LeeSeng\n",
      "3              5  data-face/LeeSeng/VID_20190908_145635.mp4-1399...  LeeSeng\n",
      "4             10      data-face/GabyNg/20190902_124535.mp4-1265.jpg   GabyNg\n",
      "...          ...                                                ...      ...\n",
      "3733        5343            data-face/XiaoYan/IMG_4749.MOV-1701.jpg  XiaoYan\n",
      "3734        5344             data-face/XiaoYan/IMG_4749.MOV-179.jpg  XiaoYan\n",
      "3735        5345             data-face/XiaoYan/IMG_4749.MOV-916.jpg  XiaoYan\n",
      "3736        5347             data-face/XiaoYan/IMG_4747.MOV-251.jpg  XiaoYan\n",
      "3737        5348      data-face/GabyNg/20190902_124535.mp4-1459.jpg   GabyNg\n",
      "\n",
      "[3738 rows x 3 columns]\n",
      "      Unnamed: 0                                           filename    label\n",
      "0              0  data-face/LeeSeng/VID_20190908_145635.mp4-607.jpg  LeeSeng\n",
      "1              3            data-face/XiaoYan/IMG_4749.MOV-2097.jpg  XiaoYan\n",
      "2              6             data-face/XiaoYan/IMG_4747.MOV-296.jpg  XiaoYan\n",
      "3              7            data-face/XiaoYan/IMG_4749.MOV-1992.jpg  XiaoYan\n",
      "4              8       data-face/GabyNg/20190902_124535.mp4-955.jpg   GabyNg\n",
      "...          ...                                                ...      ...\n",
      "1046        5325  data-face/LeeSeng/VID_20190902_091449.mp4-969.jpg  LeeSeng\n",
      "1047        5329  data-face/LeeSeng/VID_20190908_145635.mp4-222.jpg  LeeSeng\n",
      "1048        5334             data-face/XiaoYan/IMG_4749.MOV-537.jpg  XiaoYan\n",
      "1049        5336            data-face/XiaoYan/IMG_4749.MOV-1348.jpg  XiaoYan\n",
      "1050        5346            data-face/XiaoYan/IMG_4747.MOV-1002.jpg  XiaoYan\n",
      "\n",
      "[1051 rows x 3 columns]\n",
      "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator object at 0x7f07b2650828>\n",
      "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator object at 0x7f07b2650ac8>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 37s 1s/step - loss: 0.6499 - acc: 0.8936 - val_loss: 105.4420 - val_acc: 0.2979\n",
      "Learning rate: 0.001\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 28s 974ms/step - loss: 0.2548 - acc: 0.9967 - val_loss: 27.7471 - val_acc: 0.2979\n",
      "Learning rate: 0.001\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 28s 970ms/step - loss: 0.2457 - acc: 0.9997 - val_loss: 7.8242 - val_acc: 0.4062\n",
      "Learning rate: 0.001\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 29s 1s/step - loss: 0.2423 - acc: 0.9997 - val_loss: 1.2025 - val_acc: 0.6953\n",
      "Learning rate: 0.001\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 28s 977ms/step - loss: 0.2400 - acc: 0.9997 - val_loss: 0.2568 - val_acc: 0.9980\n",
      "Learning rate: 0.001\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 28s 981ms/step - loss: 0.2366 - acc: 1.0000 - val_loss: 0.2380 - val_acc: 0.9990\n",
      "Learning rate: 0.001\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 28s 949ms/step - loss: 0.2330 - acc: 1.0000 - val_loss: 0.2313 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 28s 980ms/step - loss: 0.2298 - acc: 1.0000 - val_loss: 0.2280 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 27s 946ms/step - loss: 0.2270 - acc: 0.9994 - val_loss: 0.2251 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 28s 953ms/step - loss: 0.2374 - acc: 0.9958 - val_loss: 1.3931 - val_acc: 0.8311\n",
      "Learning rate: 0.001\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 27s 939ms/step - loss: 0.2380 - acc: 0.9964 - val_loss: 1.9001 - val_acc: 0.7266\n",
      "Learning rate: 0.001\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 27s 931ms/step - loss: 0.2207 - acc: 0.9992 - val_loss: 0.5521 - val_acc: 0.8994\n",
      "Learning rate: 0.001\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 27s 926ms/step - loss: 0.2183 - acc: 0.9983 - val_loss: 0.2278 - val_acc: 0.9912\n",
      "Learning rate: 0.001\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 27s 941ms/step - loss: 0.2125 - acc: 0.9997 - val_loss: 0.3105 - val_acc: 0.9746\n",
      "Learning rate: 0.001\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 27s 924ms/step - loss: 0.2096 - acc: 0.9994 - val_loss: 0.2073 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 26s 913ms/step - loss: 0.2050 - acc: 1.0000 - val_loss: 0.2030 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 26s 894ms/step - loss: 0.2024 - acc: 0.9994 - val_loss: 0.2003 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 27s 919ms/step - loss: 0.1991 - acc: 0.9997 - val_loss: 0.1961 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 26s 880ms/step - loss: 0.1967 - acc: 0.9991 - val_loss: 0.2058 - val_acc: 0.9971\n",
      "Learning rate: 0.001\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 26s 910ms/step - loss: 0.1922 - acc: 0.9997 - val_loss: 0.1896 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 26s 888ms/step - loss: 0.1884 - acc: 0.9997 - val_loss: 0.1952 - val_acc: 0.9941\n",
      "Learning rate: 0.001\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 26s 885ms/step - loss: 0.1845 - acc: 1.0000 - val_loss: 0.1919 - val_acc: 0.9971\n",
      "Learning rate: 0.001\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 25s 873ms/step - loss: 0.1811 - acc: 1.0000 - val_loss: 0.1792 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 25s 869ms/step - loss: 0.1776 - acc: 1.0000 - val_loss: 0.1758 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 25s 867ms/step - loss: 0.1743 - acc: 1.0000 - val_loss: 0.1725 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 25s 860ms/step - loss: 0.1709 - acc: 1.0000 - val_loss: 0.1692 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 25s 857ms/step - loss: 0.1678 - acc: 1.0000 - val_loss: 0.1665 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 24s 845ms/step - loss: 0.1645 - acc: 1.0000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 24s 838ms/step - loss: 0.1610 - acc: 1.0000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 24s 835ms/step - loss: 0.1577 - acc: 1.0000 - val_loss: 0.1562 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 24s 817ms/step - loss: 0.1547 - acc: 1.0000 - val_loss: 0.1532 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 29s 983ms/step - loss: 0.1515 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 28s 968ms/step - loss: 0.1483 - acc: 1.0000 - val_loss: 0.1469 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 28s 969ms/step - loss: 0.1452 - acc: 1.0000 - val_loss: 0.1443 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 28s 981ms/step - loss: 0.1421 - acc: 1.0000 - val_loss: 0.1410 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 28s 970ms/step - loss: 0.1398 - acc: 0.9997 - val_loss: 0.1377 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 29s 983ms/step - loss: 0.1364 - acc: 1.0000 - val_loss: 0.1348 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 27s 939ms/step - loss: 0.1335 - acc: 1.0000 - val_loss: 0.1319 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 27s 944ms/step - loss: 0.1427 - acc: 0.9961 - val_loss: 2.7266 - val_acc: 0.8027\n",
      "Learning rate: 0.001\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 28s 956ms/step - loss: 0.1687 - acc: 0.9892 - val_loss: 54.1347 - val_acc: 0.4590\n",
      "Learning rate: 0.001\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 27s 939ms/step - loss: 0.1489 - acc: 0.9964 - val_loss: 141.3560 - val_acc: 0.3066\n",
      "Learning rate: 0.001\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 27s 941ms/step - loss: 0.1387 - acc: 0.9956 - val_loss: 5.1228 - val_acc: 0.7627\n",
      "Learning rate: 0.001\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 28s 957ms/step - loss: 0.1349 - acc: 0.9984 - val_loss: 0.1487 - val_acc: 0.9932\n",
      "Learning rate: 0.001\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 26s 900ms/step - loss: 0.1279 - acc: 1.0000 - val_loss: 0.2936 - val_acc: 0.9629\n",
      "Learning rate: 0.001\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 27s 914ms/step - loss: 0.1256 - acc: 0.9997 - val_loss: 0.1230 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 27s 931ms/step - loss: 0.1234 - acc: 0.9995 - val_loss: 0.1209 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 27s 916ms/step - loss: 0.1222 - acc: 0.9992 - val_loss: 0.1251 - val_acc: 0.9980\n",
      "Learning rate: 0.001\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 26s 907ms/step - loss: 0.1174 - acc: 1.0000 - val_loss: 0.1160 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 26s 899ms/step - loss: 0.1164 - acc: 0.9994 - val_loss: 0.1185 - val_acc: 0.9980\n",
      "Learning rate: 0.001\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 25s 870ms/step - loss: 0.1129 - acc: 1.0000 - val_loss: 0.1116 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 26s 910ms/step - loss: 0.1104 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 25s 861ms/step - loss: 0.1082 - acc: 1.0000 - val_loss: 0.1070 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 26s 892ms/step - loss: 0.1059 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 25s 848ms/step - loss: 0.1037 - acc: 1.0000 - val_loss: 0.1026 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 26s 883ms/step - loss: 0.1016 - acc: 1.0000 - val_loss: 0.1005 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 24s 842ms/step - loss: 0.0995 - acc: 1.0000 - val_loss: 0.0984 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 25s 864ms/step - loss: 0.0974 - acc: 1.0000 - val_loss: 0.0964 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 25s 852ms/step - loss: 0.0955 - acc: 1.0000 - val_loss: 0.0944 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 24s 842ms/step - loss: 0.0935 - acc: 1.0000 - val_loss: 0.0924 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 24s 838ms/step - loss: 0.0916 - acc: 1.0000 - val_loss: 0.0905 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 23s 809ms/step - loss: 0.0902 - acc: 0.9997 - val_loss: 0.0887 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 29s 1s/step - loss: 0.0893 - acc: 0.9995 - val_loss: 0.0877 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 28s 974ms/step - loss: 0.0864 - acc: 1.0000 - val_loss: 0.0875 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 28s 975ms/step - loss: 0.0845 - acc: 1.0000 - val_loss: 0.0872 - val_acc: 0.9990\n",
      "Learning rate: 0.001\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 28s 960ms/step - loss: 0.0828 - acc: 1.0000 - val_loss: 0.0855 - val_acc: 0.9990\n",
      "Learning rate: 0.001\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 28s 979ms/step - loss: 0.0810 - acc: 1.0000 - val_loss: 0.0827 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 27s 948ms/step - loss: 0.0801 - acc: 0.9997 - val_loss: 0.0785 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 28s 976ms/step - loss: 0.0780 - acc: 1.0000 - val_loss: 0.0769 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 27s 938ms/step - loss: 0.0761 - acc: 1.0000 - val_loss: 0.0753 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 28s 949ms/step - loss: 0.0745 - acc: 1.0000 - val_loss: 0.0737 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 28s 953ms/step - loss: 0.0730 - acc: 1.0000 - val_loss: 0.0721 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 27s 925ms/step - loss: 0.0714 - acc: 1.0000 - val_loss: 0.0706 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 27s 932ms/step - loss: 0.0699 - acc: 1.0000 - val_loss: 0.0691 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 27s 931ms/step - loss: 0.0684 - acc: 1.0000 - val_loss: 0.0676 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 26s 914ms/step - loss: 0.0669 - acc: 1.0000 - val_loss: 0.0662 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 27s 935ms/step - loss: 0.0656 - acc: 1.0000 - val_loss: 0.0648 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 26s 893ms/step - loss: 0.0641 - acc: 1.0000 - val_loss: 0.0634 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 26s 896ms/step - loss: 0.0628 - acc: 1.0000 - val_loss: 0.0621 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 26s 895ms/step - loss: 0.0615 - acc: 1.0000 - val_loss: 0.0608 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 26s 907ms/step - loss: 0.0602 - acc: 1.0000 - val_loss: 0.0595 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 26s 893ms/step - loss: 0.0589 - acc: 1.0000 - val_loss: 0.0583 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 25s 861ms/step - loss: 0.0582 - acc: 1.0000 - val_loss: 0.0581 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 26s 894ms/step - loss: 0.0581 - acc: 1.0000 - val_loss: 0.0580 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 25s 871ms/step - loss: 0.0579 - acc: 1.0000 - val_loss: 0.0579 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 25s 865ms/step - loss: 0.0579 - acc: 1.0000 - val_loss: 0.0577 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 25s 858ms/step - loss: 0.0577 - acc: 1.0000 - val_loss: 0.0576 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 25s 857ms/step - loss: 0.0575 - acc: 1.0000 - val_loss: 0.0575 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 24s 844ms/step - loss: 0.0574 - acc: 1.0000 - val_loss: 0.0573 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 24s 837ms/step - loss: 0.0574 - acc: 1.0000 - val_loss: 0.0572 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 24s 828ms/step - loss: 0.0571 - acc: 1.0000 - val_loss: 0.0571 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 23s 810ms/step - loss: 0.0570 - acc: 1.0000 - val_loss: 0.0569 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 29s 994ms/step - loss: 0.0569 - acc: 1.0000 - val_loss: 0.0568 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 28s 978ms/step - loss: 0.0567 - acc: 1.0000 - val_loss: 0.0567 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 28s 968ms/step - loss: 0.0566 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 28s 970ms/step - loss: 0.0564 - acc: 1.0000 - val_loss: 0.0564 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 28s 957ms/step - loss: 0.0563 - acc: 1.0000 - val_loss: 0.0562 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 28s 971ms/step - loss: 0.0562 - acc: 1.0000 - val_loss: 0.0561 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 28s 960ms/step - loss: 0.0560 - acc: 1.0000 - val_loss: 0.0559 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 28s 952ms/step - loss: 0.0559 - acc: 1.0000 - val_loss: 0.0558 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 27s 944ms/step - loss: 0.0557 - acc: 1.0000 - val_loss: 0.0556 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = createModel(target_size)\n",
    "print('model summary:', model.summary())\n",
    "\n",
    "filepath = modelname + \".hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=0,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "# Log the epoch detail into csv\n",
    "csv_logger = CSVLogger(modelname + '.csv')\n",
    "# callbacks_list  = [checkpoint,csv_logger]\n",
    "\n",
    "LRScheduler = LearningRateScheduler(lrSchedule)\n",
    "callbacks_list = [checkpoint, csv_logger, LRScheduler]\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.10,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "vdatagen = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    rotation_range=0,\n",
    "    zoom_range=0,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=tdf, x_col=\"filename\", y_col=\"label\",\n",
    "                                              class_mode=\"categorical\", target_size=target_size,\n",
    "                                              shuffle=True,\n",
    "                                              batch_size=batch_size)\n",
    "\n",
    "valid_generator = vdatagen.flow_from_dataframe(dataframe=vdf, x_col=\"filename\", y_col=\"label\",\n",
    "                                               class_mode=\"categorical\", target_size=target_size,\n",
    "                                               shuffle=True,\n",
    "                                               batch_size=batch_size)\n",
    "print(tdf)\n",
    "print(vdf)\n",
    "print(train_generator)\n",
    "print(valid_generator)\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "\n",
    "# Change from 100 to epochs as testing shows 50 epochs is sufficient to generate a validation accuracy of more than 85%\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    validation_data=valid_generator,\n",
    "                    epochs=epoch_size,\n",
    "                    verbose=1,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks=callbacks_list)\n",
    "# ......................................................................\n",
    "\n",
    "# Now the training is complete, we get\n",
    "# another object to load the weights\n",
    "# compile it, so that we can do\n",
    "# final evaluation on it\n",
    "# modelGo.load_weights(filepath)\n",
    "# modelGo.compile(loss='categorical_crossentropy',\n",
    "#                 optimizer=optimizers.Adam(lr=0.001),\n",
    "#                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(modelname + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxcZZ33/c+vqnpL0tkDhgRIxABGYABjQGVuQfAxwAguMwzM4MgsxlFAnFsdYW5Fxbmfce7Hm3HDhXFwcAFkGMQoUTZZhpEtAgIJCQmb6SwkZKOT3mr5PX+cU53qSnXVqe46qVTV9/169au2U1VXdXXXt37Xdc51mbsjIiKtK1HvBoiISH0pCEREWpyCQESkxSkIRERanIJARKTFKQhERFqcgkBaipn9u5n9Y8RtXzKzM+Juk0i9KQhERFqcgkCkAZlZqt5tkOahIJADTtgl82kze8rM9pjZv5nZwWb2SzPrNbO7zWxawfbnmNlKM9tpZveZ2RsLbjvBzB4P7/cToLPouf7IzJ4M7/sbMzsuYhvPNrMnzOw1M1tvZl8ouv2U8PF2hrdfFF7fZWb/18xeNrNdZvZgeN2pZtZT4vdwRnj+C2Z2i5n9yMxeAy4ys8Vm9lD4HJvM7Jtm1l5w/zeZ2V1mtt3MXjGzfzCz15lZn5nNKNjuRDPbamZtUV67NB8FgRyoPgC8CzgSeA/wS+AfgFkEf7cfBzCzI4EbgU+Ety0Hfm5m7eGH4m3AD4HpwH+Ej0t43xOA64CPADOA7wLLzKwjQvv2AH8BTAXOBj5qZu8NH/fwsL3fCNt0PPBkeL+vAG8G3ha26e+BXMTfybnALeFz/hjIAn8HzATeCpwOfCxsQzdwN/Ar4BDgDcA97r4ZuA84r+BxPwjc5O7piO2QJqMgkAPVN9z9FXffAPwX8Ii7P+HuA8BPgRPC7f4UuN3d7wo/yL4CdBF80J4MtAFfdfe0u98CPFbwHEuB77r7I+6edffrgcHwfmW5+33u/rS759z9KYIwekd4858Bd7v7jeHzbnP3J80sAfwVcJm7bwif8zfuPhjxd/KQu98WPme/u//W3R9294y7v0QQZPk2/BGw2d3/r7sPuHuvuz8S3nY9cCGAmSWBCwjCUlqUgkAOVK8UnO8vcXlSeP4Q4OX8De6eA9YDc8LbNvjImRVfLjh/OPDJsGtlp5ntBA4N71eWmZ1kZveGXSq7gL8l+GZO+BjPl7jbTIKuqVK3RbG+qA1HmtkvzGxz2F30/0ZoA8DPgIVmNp+g6trl7o+OsU3SBBQE0ug2EnygA2BmRvAhuAHYBMwJr8s7rOD8euB/u/vUgp8J7n5jhOe9AVgGHOruU4DvAPnnWQ8cUeI+rwIDo9y2B5hQ8DqSBN1KhYqnCv42sBpY4O6TCbrOCtvw+lIND6uqmwmqgg+iaqDlKQik0d0MnG1mp4eDnZ8k6N75DfAQkAE+bmZtZvZ+YHHBff8V+Nvw272Z2cRwELg7wvN2A9vdfcDMFhN0B+X9GDjDzM4zs5SZzTCz48Nq5TrgajM7xMySZvbWcEziOaAzfP424LNApbGKbuA1YLeZHQ18tOC2XwCzzewTZtZhZt1mdlLB7T8ALgLOQUHQ8hQE0tDcfQ3BN9tvEHzjfg/wHncfcvch4P0EH3jbCcYTbi247wrgw8A3gR3AunDbKD4GXGVmvcCVBIGUf9zfA2cRhNJ2goHiPwhv/hTwNMFYxXbgn4GEu+8KH/N7BNXMHmDEXkQlfIoggHoJQu0nBW3oJej2eQ+wGVgLnFZw+38TDFI/7u6F3WXSgkwL04i0JjP7NXCDu3+v3m2R+lIQiLQgM3sLcBfBGEdvvdsj9aWuIZEWY2bXExxj8AmFgIAqAhGRlqeKQESkxTXcxFUzZ870efPm1bsZIiIN5be//e2r7l58bArQgEEwb948VqxYUe9miIg0FDMbdTdhdQ2JiLQ4BYGISItTEIiItLiGGyMoJZ1O09PTw8DAQL2bEqvOzk7mzp1LW5vWDxGR2mmKIOjp6aG7u5t58+YxcqLJ5uHubNu2jZ6eHubPn1/v5ohIE4mta8jMrjOzLWb2zCi3m5l93czWWbAk4Yljfa6BgQFmzJjRtCEAYGbMmDGj6aseEdn/4hwj+HdgSZnbzwQWhD9LCeZWH7NmDoG8VniNIrL/xdY15O4PmNm8MpucC/wgXD3qYTObamaz3X1TXG0q5u70p7P0D2X3WfEj2ADcc1gujXmGZC5LwjMkPEvhGiFmwWogZoZ1TaWja2LJD213ZyiTI51zUgkjmQi2SWdyDGVzZHKOAUnP0jG0HXfHAffwOcxI79nByh9/hmzOyXqC3hnH0X/ISXRM6GZgKE37K79j0qtPsGnKiWyffDTukM05Q9kcQ5kcnssxbeD3HLbzMSamt8XwWx0fMyORgGT4+8vmnGxu5LvTP+dtnPiOc5kyofqxkh17hnjh1T28+OoeNuzoJ2HQnshxwsab6MztIWmQSCQZ6D6UgelvZGjaG0i/toXElpV0bH+OofbJ9E09msHpR5HI9NGxbTUTd62hfei1mrz+sTAL/pYSBqmEkUgYSTOy+b+3rDOY6KSvbTp9bTMYSnaRX7+mLdvHhPR2Jqa3057tIxn+XZrZ8O9e09AcOKafeC5HnviOyhtWqZ5jBHMYufReT3jdPkFgZksJqgYOO+yw4purls7m2LxrgN6BDJlc6XXDk+Q40npos2zJ2wv/N3bu6uWG237JxRedx86BPl567XVM6WqjI5Uk504u5wxmcuwezJDO7n2+i//iT/inb3yPyVOmjHjsOfYqXdZLqf+/VLqXo5/7LgAJc3gBBj3FKp/HCbaRKdY3vO3Psm/jK5k/YY93cUriGU5JPM3bk88wx/YGQM4bq8pImPP07+/hLQ9O5NSjZnHBSYdx2lEHjdhm3ZZe7lq1he7OFNMntpPNOY++uJ3fPP8qz2/ds89jnpZ4go+0Xw0Ev4+EVf/BdyD/Hqt5PQfy6xB4bPJsaLIgiMzdrwWuBVi0aNG4v57s6k+zo2+IqV3tdHelmNieIlH092+ZfpLbsuS6pmPtkyCZwhJtkExBIkWwDnlgx9CLfPuGn/PRv7mICRgdiSSv9g6RzqRJpYJfcSqRYGJHkkkdHbSnEmRzzm3LfoE7tKcStKcSpBKG57Kktr5EtnM6uSmHkjTDDHIOuZyT3fEsGy7bSEcqQTLbT+7lh0i8eD8LNq0gPe3NvDrvVBJzT2DCyhs5Z8W1nJN6BPMgzLxzKjb/f8ARp8HrT4Pp8w+4/YezOSedzTGYyQXf1lMJ2hIJEuEb5Ld+mCNffJgPHnU4y363kTtXvcK733QwXzznGGZMaufaB17ga3evZSg7MuAntid5x+Ht/ONBjzDw5qUcPmsqc6dNwAz4xZ34MxN49WNrGLI2hoaGYPsLJLespG37cyQmHUT7nGOZOPdYfGAngxueIrd5JbRPIjX7GDrmHEvb5INKvJr9I5sLvvkH1WaOdFj9tacSTGhPMbE9SSrTB3u2wO6tkC4Iw7YJMHEWTDqIXGoi6bCKyOX2/l0mi/85pG5OqrzJmNQzCDYQrC2bNze8LnbpbA4z49DpXaP3u2eCvEl0TYPOyWUf7x+uuILnn3+eE09/L22pFJ2TpjJ16lRWr1nDqmdX88fvfz89PesZGBjgsssuY+nSpQDMO/wwVvzqRrZ3HMyZZ7+HU045hd88+ABzDprOz35+O13JvR/TSYNkwkglExw6Pb+0bSdMOwuOP2vfRh16Fbzto/Dod6F9EhxxGjb7eEgkq/597U9B10SSzrbS7bSOyXRk9/C5P1rI5Wcezff+60W+evdznHH1/cyZ2sWaV3o5+7jZfO7shZjBjr4hMlnnqNd107bqVvjPr8GJJ8Cs9wUP6A7P3w1HvJNZ0/LvcxccdAIcfcK+DeieTses1wPvjeX1j0UyYXS1J+lqL/PeJidBxySYXnIZYyAYMOwAOlIH9t+I1F49g2AZcImZ3UQQdLtqMT7wxZ+vZNXG8v21g5kc2Zwzodw/jmch3Q9te1g4Zxqff8+bRt30y1/+Ms888wxP3v9z7rvvfs7+4MU888wzw7t5fv/71zF9+nT6+/t5y1vewgc+8AFmzJgBnoPsIOx+hbVr13LjDTfwr//4Cc5b+mn+c9lyLrzwwjH9DoZNng1nfGF8j3Gg6eiGwWAK/bZkgo+eegRnHfs6PnvbM6ze3Mt3LjyRJcfMHt784Mmde+8b3o+nboY3hUGwZRW81gPv+Pv99QpEDjixBYGZ3QicCsw0sx7g80AbgLt/B1hOsK7rOqAP+Mu42lLM3am4A85YBsgSSSDH4sWLR+zr//Wvf52f/vSnAKxfv561a9cGQZAfcO7fyfx5h3P80fNhx4u8+S2Leemll6p//lbQ0Q3ZIcgMQipY2/3wGRP54V+fRC7nw11IJQ2FXSJr74Q922DiDHjuV8F1C/6fmBsucuCKc6+hCyrc7sDFtX7ect/c89Zs7qWzLcHhMyaOvlH/DtjxEsw6Gtq6oj15IgW5HBMn7n3c++67j7vvvpuHHnqICRMmcOqpp+49FsCBzqnQn6UjlYDdWyDZTrJjIv179h3UFKAj7L4ZeA0mjZxRt2wIwN4gyGVg5a2w+MPw3J0w+w+C6kmkRR1oY4Wxcw8GI9uSFV66h4ONVvlX1N3dTW9vL1iScJ/T4dt27drFtGnTmDBhAqtXr+bhhx8Obsjlgm1THTD5kOB8eg9MnEnlcqWFdXQHp4Nj2F1zqBdSXXDQm4Luob7t0PMoLHh3bdso0mAaYq+hWsq5k3OvaRDMmDGDt7/97Rxz0ql0tSc4eM7hw7ctWbKE73znO7zxjW/kqKOO4uSTTw4bMhScJtqgoz2oJhIp6JoxlpfVOvIVweAYltod2gPtE+G48+Duz8Oj/xq8z0eWO+5RpPm1XBCks8G39bZkhW/d+W/1Eb+d33DDDSO7k0IdHR388pe/3PcOg7289MjtMGM2Mzu6eWbV6qBKSCT41Kc+Fek5W9JwRTCOIDj2T+DuL8AD/1+w6+QhJfYOEmkhLdc1lD+gq5YVwTAL90LKlT4IbYRsWBEk2/del2i5t6N64w6CSTBlDsz/Q8il4Q3v0u9dWl7L/QfkK4JUxYogf0BSFf31+X30PUIQZPJBoCmlqzKuINgdVAQAx/1pcHqkxgdEWrBrKKwIKn0LdA+qgWoGbvNBkMtU3jY7FIwPVFNxSMEYwVgGi/fsDZLjzg+Oqn3je2rXNpEG1XKfQplsbnhirrI8V/2HtIW5GrVrSNVA9TrHGQT5iiCZgmPef8AfaS2yP7RcEKSzTqrS+ACEXUNV7sZZTddQNj1yfECiSXUEv7cxdw1Nqn2bRBpcCwZBhGMIYIwVgQX3qVQRuIcVgYJgTAqmmajKYMEYgYgMa8Eg8Mq7jkJVQbBz506+9a1vBRcsWTkIchmCg8na+epXv0pfX1/57WWksQZBYdeQiAxrqSDIuZPJRa0IfGxBkEhVDoKCXUcVBGMwliDIpoMJ/tQ1JLKPltprKDN8DEHUiiDaGMHll1/O888/z/HHH8+7TlnEQTNncPPtv2ZwcJD3ve99fPGLX2TPnj2cd9559PT0kM0M8blLPsQrAyk2btzIaaedxsyZM7n33nvH8/JaR8fkYK6hauTnGVJFILKP5guCX14Om58ueVPSndcPZelsS1Q+iCjdFwRBqgtedyyc+eVRNx2ehvrJJ7nzluu55We38+ijj+LunHPOOTzwwANs3bqVQw45hNtvvx12v8KunjVMOfJtXP21b3Lvvfcyc+bM8bzq1tIxGV6rcukKBYHIqFqqayi/9mq0ReDHthDanff9N3fe99+ccMIJnHjiiaxevZq1a9dy7LHHctddd/GZz3yG//qvB5kyZcreI5GlOmPpGhoOAnUNiRRrvoqgzDf3Hb2DbNrVz8LZk6HSOMErwVKETDu8/HZFHLji0r/iI3//pX1ue/zxx1m+fDmf/dL/4fQ/XMyV//yNqh5bQmMKgt3BqYJAZB8tVRFkcsESlZHWYK1ijGB4Gmrg3WecxnU33cbu8PKGDRvYsmULGzduZMKECVx44YV8+mMX8fjTq/e5r0Q0ropAXUMixZqvIigjnQl2HY3UNVTF7qPD01Afcwxnnv4O/uy9S3jr294KGJMmTeJHP/oR69at49Of/jSJRII2Mnz7X4LKZenSpSxZsoRDDjlEg8VRdXQHewAVrFJW0XBFoCAQKdZaQZDLVZ5jKK/KA8puuOGG4Ezfdtj5Mpf9w5cgtXe93COOOIJ3v/vdwa6lm5+C7mBFrEsvvZRLL7008vMII9ckiBwEGiMQGU1LdQ1VdVQxjG1CuESFqahLTT8t1RnLfEOqCERGFWsQmNkSM1tjZuvM7PIStx9uZveY2VNmdp+ZzY2rLcESlU5bKkq3UHWL0oxQaU2CbDo4VRCM3VimotYYgcioYgsCM0sC1wBnAguBC8xsYdFmXwF+4O7HAVcB/zTW53Mvv7tnNue4O6koXUO1qAhGm3huHBVBpdfYMsYVBOoaEikWZ0WwGFjn7i+4+xBwE3Bu0TYLgV+H5+8tcXsknZ2dbNu2rewHZeQlKmE/dQ1VNwW1u7Nt2zY6Ozsrb9zsxhQEu4Mxm2RLDYuJRBLnf8UcYH3B5R7gpKJtfge8H/ga8D6g28xmuPu2wo3MbCmwFOCwww7b54nmzp1LT08PW7duHbUxA+ksr+4ewnd0sClV4QM+m4beLbA1B+1bym9bzHOwawt0DkFnifb0bQv2dtm1urrHJQi8uXNj6z1rHPnB4mqmmdCEcyKjqvfXo08B3zSzi4AHgA3APl+l3f1a4FqARYsW7fO1v62tjfnz55d9opse/T2XL3uaBz9zGnOnTSjfqo1PwC3nwfk3wtFnRXwpw42FL70D3noxvOuL+97+4/Ng92b4yAPVPa7sNVwRKAhEaiHOINgAHFpweW543TB330hQEWBmk4APuPvOOBrTN5Slqy3JQd0RulbSA8Fp2xi6YcygayoM7Cp9+8Au6JxS/ePKXoW7j0Y12KvxAZFRxDlG8BiwwMzmm1k7cD6wrHADM5tpNtwRfwVwXVyN+atT5rPqqnfTXqlbCIIJ5yCYcG4sOqfAwCh5piAYv1RHsN5ztYPFqghESootCNw9A1wC3AE8C9zs7ivN7CozOyfc7FRgjZk9BxwM/O+42gNRJ5sDMvmKYKxBoIogVmbVTzOhIBAZVaxjBO6+HFhedN2VBedvAW6Jsw1jku4PTsccBFOgf0fp2wZ2BkEh4zOWIJh0UHztEWlgLXVkcWT5iiA1xl01u6aW7hrKDAXdTqoIxq9jcvVHFqsiEClJQVBKLSqCUl1D+Q8uVQTj1zl5DF1DGiwWKUVBUMq4g2Aq9O/cO1VFXj4cVBGMX0e3dh8VqREFQSnDXUNjDIKuqcEUE/lpDfLy3UUKgvGrZowgm4FMvyoCkVEoCEpJ90MiNfbpCPIf9MXjBKoIaqeaIEhrwjmRchQEpaT7x14NwN4xgOJxgn5VBDVTTRBo5lGRshQEpWT6x3ZUcV7+g75fFUFsOrqDLrzMUOVtNfOoSFkKglLSA2MfKIZgjAD2rQjyl7u019C4dYRhGqUq0KI0ImUpCErJjLdrqMwYQSIFbRUmvZPKqpl4Tl1DImUpCEpJj7drKPzGX6prqHPK2FY+k5GqWZMgHwQd6hoSKUVBUMq4B4vzFUFx19BOjQ/USlVBkO8aUhCIlKIgKCUzzjGCRDKYAqFU15CCoDaqCYJBjRGIlKMgKGW8g8VQegbSgV2aXqJWhtck0BiByHgpCErJ9I99wrm8zimjjxHI+HWOIQjaFAQipSgISkn3j78imDQLdr8y8joFQe1UO0aQbIdUe7xtEmlQCoJSahEE3YdA76aR1ykIaifVGeyKG3WvIXULiYxKQVBKZmD8XUOTZwcVQTYTXE4PBI+rIKiNalYp0xTUImUpCIq516gieB14DvZsDS5reonaixwEuxUEImUoCIplBgEff0XQfUhw2rsxOB2eXmLa+B5X9uqYDAMRB4vVNSQyqliDwMyWmNkaM1tnZpeXuP0wM7vXzJ4ws6fM7Kw42xNJJr8ozTingZg8Ozh9LRwnUEVQe1GXq9QylSJlxRYEZpYErgHOBBYCF5jZwqLNPgvc7O4nAOcD34qrPZGlw0VpxjPFBBRUBAqC2GiMQKQm4qwIFgPr3P0Fdx8CbgLOLdrGgXCHcKYAG2NsTzT5imA8U0wATJwJliwIAq1FUHNRl6tURSBS1hiX4IpkDrC+4HIPcFLRNl8A7jSzS4GJwBkxtiea4fWKx1kRJJLBgPFrCoLYtHXtreDK0RiBSFn1Hiy+APh3d58LnAX80Mz2aZOZLTWzFWa2YuvWrfG2KD3O9YoLdc/ed7BYU0zUTqpz7/rS5SgIRMqKMwg2AIcWXJ4bXlfor4GbAdz9IaATmFn8QO5+rbsvcvdFs2bNiqm5oeHB4hoEweTZ0Ls5OD+wC5Id4680ZK9UR7iXVxm5LKT7NEYgUkacQfAYsMDM5ptZO8Fg8LKibX4PnA5gZm8kCIKYv/JXMDxYXKOKoHCvIXUL1VaUiiDdF5xqLQKRUcUWBO6eAS4B7gCeJdg7aKWZXWVm54SbfRL4sJn9DrgRuMjdPa42RTI8WFyDb+7ds2FwV9A1oSCovbZO8Ozeo7dL0cyjIhXFOViMuy8Hlhddd2XB+VXA2+NsQ9XStewaCnchfW2TgiAO+bDODEBylG/8g1qURqSSeg8WH3hqGQTd4UFlvZuCKakVBLU1HARlxgm0cL1IRQqCYpka7jU0ueCgsoFd0KU9hmoq1RGc5rvzSlHXkEhFCoJitTqOAILjCABe26iuoThEqgjyQaCuIZHRKAiKpWt0ZDEER762d++tCBQEtTVcEZTZc0hdQyIVKQiKZfqD/f0TNfrVTJ4N21+AXFpBUGuFg8WjUdeQSEUKgmLpgdoe9NU9G7asDs4rCGpruCIo0zVUyzEfkSalICiW6a/th0b3bNj1++C8ppeorfz7VK4iyIeE1isWGZWCoFi6v7YVQX5dAlBFUGtRKoLsUHCaVBCIjEZBUCzdP/5FaQrl1yUAVQS1lh8jSJfZfTSbDk4VBCKjUhAUq8XC9YVUEcQnakVgyWBacBEpSUFQLD1Qm6OK80ZUBAqCmoqy11B2SNWASAUKgmLpvtpWBPmDykBBUGuRKoK0gkCkglgnnWtImRpXBJMOBksE4aI9V2orckXQtn/aI9KgFATF0v21DYJkCiYeBGa1e0wJRJliIjuoikCkAgVBsVoPFkMwYFxuzxYZm0Qi+JAvWxGkVRGIVKAgKFbrigDgiNP3rlkstZXqrLzXkCoCkbIUBMXS/bWvCE7/XG0fT/ZKdZSfhlqDxSIVRdpryMxuNbOzzay59zLK5YI+5VoeUCbxilIRaJBepKyoH+zfAv4MWGtmXzazo2JsU/3k+5prOcWExCvVoeMIRMYpUhC4+93u/ufAicBLwN1m9hsz+0sza56ROM1U2XgqVgTqGhKpJHJXj5nNAC4C/gZ4AvgaQTDcVeY+S8xsjZmtM7PLS9z+L2b2ZPjznJntrPoV1FK6LzhVRdA4IlUEzfNdRSQOkQaLzeynwFHAD4H3uPum8KafmNmKUe6TBK4B3gX0AI+Z2TJ3X5Xfxt3/rmD7S4ETxvQqaiWd7xrSGEHDSHVVWI9gECbM2H/tEWlAUfca+rq731vqBndfNMp9FgPr3P0FADO7CTgXWDXK9hcAn4/Ynnjk9z6p9V5DEp9UBwy+NvrtOo5ApKKoXUMLzWx4DmUzm2ZmH6twnznA+oLLPeF1+zCzw4H5wK9HuX2pma0wsxVbt26N2OQxGK4INEbQMFKde9+3UjRYLFJR1CD4sLsP99+7+w7gwzVsx/nALe6eLXWju1/r7ovcfdGsWbNq+LRF8mMEqggaR8UxAg0Wi1QSNQiSZnsnywn7/yv9d20ADi24PDe8rpTzgRsjtiU+GY0RNBwdWSwyblGD4FcEA8Onm9npBB/av6pwn8eABWY238zaCT7slxVvZGZHA9OAh6I3OybDew2pa6hh6DgCkXGLOlj8GeAjwEfDy3cB3yt3B3fPmNklwB1AErjO3Vea2VXACnfPh8L5wE3u7lW3vtbyE8MpCBqHjiMQGbdIQeDuOeDb4U9k7r4cWF503ZVFl79QzWPGSkHQeNo6dRyByDhFPY5gAfBPwEJgeCTV3V8fU7vqQ0HQeFKdwfxQ7vuu+eCu9QhEIog6RvB9gmogA5wG/AD4UVyNqpvhINBgccMot1xlLhOcKghEyooaBF3ufg9g7v5y2J1zdnzNqpNMP1hSXQmNZHiVshJTUWeHglO9nyJlRR0sHgynoF4bDgBvACbF16w6SferGmg05SqCfBDktxGRkqJWBJcBE4CPA28GLgQ+FFej6ibdp/GBRlNuAftsOjhVRSBSVsWKIDx47E/d/VPAbuAvY29VvaQHNPNoo4lSEWiMQKSsihVBOO3DKfuhLfWX7lPXUKMpWxEoCESiiDpG8ISZLQP+A9iTv9Ldb42lVfUSx8L1Eq/hIChREWQ0WCwSRdQg6AS2Ae8suM6B5gqCzIBWJ2s0qghExi3qkcXNOy5QKN0HnVMrbycHjnwQlJqKeniwWEEgUk7UI4u/T1ABjODuf1XzFtVTegC6VRE0lOHB4nIVgbqGRMqJ2jX0i4LzncD7gI21b06daffRxlNujGA4CHQcgUg5UbuG/rPwspndCDwYS4vqSYPFjadsRaCuIZEooh5QVmwBcFAtG3JAyOjI4oYTabBYXUMi5UQdI+hl5BjBZoI1CppLul/LVDYaHVAmMm5Ru4a6425I3eWywQeHKoLGku/K0+6jImMWqWvIzN5nZlMKLk81s/fG16w60FoEjSmRAktUqAjUNSRSTtQxgs+7+678BXffCXw+nibViYKgMZmFy1WWm4ZaFYFIOVGDoNR2UXc9bQxauL5xpTpGqQi015BIFFGDYIWZXW1mR4Q/VwO/rXQnM1tiZmvMbJ2ZXT7KNueZ2SozW2lmN1TT+JrK9zErCBpPapR1i4fXI1AQiJQTNQguBYaAnwA3Aafn33EAABBfSURBVAPAxeXuEE5ffQ1wJsFaxxeY2cKibRYAVwBvd/c3AZ+oqvW1lK8INNdQ4xm1IlDXkEgUUfca2gOU/EZfxmJgnbu/AGBmNwHnAqsKtvkwcI277wifZ0uVz1E7GiNoXKNWBGHXUEKDxSLlRN1r6C4zm1pweZqZ3VHhbnOA9QWXe8LrCh0JHGlm/21mD5vZklGef6mZrTCzFVu3bo3S5Opp4frGleocZRrqwWCvosRYj5sUaQ1R/0NmhnsKARB+g6/FkcUpgqOUTwUuAP61MHAKnu9ad1/k7otmzZpVg6ctYTgIdEBZwyk3RqBuIZGKogZBzswOy18ws3mUmI20yAbg0ILLc8PrCvUAy9w97e4vAs8RBMP+p4qgcaU6Rp+GWscQiFQUNQj+F/Cgmf3QzH4E3E8wyFvOY8ACM5tvZu3A+cCyom1uI6gGMLOZBF1FL0RsU21lNEbQsFQRiIxLpCBw918Bi4A1wI3AJ4ESR/CMuE8GuAS4A3gWuNndV5rZVWZ2TrjZHcA2M1sF3At82t23jemVjFe+ItBeQ42n3HEEmoJapKKok879DXAZQffOk8DJwEOMXLpyH+6+HFhedN2VBecd+J/hT33pgLLGVbYiUNeQSCVRu4YuA94CvOzupwEnADvL36XB5PuYNfto4yl3HIG6hkQqihoEA+4+AGBmHe6+GjgqvmbVQbovCAHtath4yh1HoCAQqSjqfEE94W6dtwF3mdkO4OX4mlUHWp2scbWNchxBdlBdQyIRRD2y+H3h2S+Y2b3AFOBXsbWqHrQ6WePSXkMi41L1DKLufn8cDak7rU7WuFId4Nl9jxvQcQQikahDPC+tiqBhjbZusSoCkUgUBHkaI2hcw0FQNE6QHdq7prGIjEpBkJfu1zxDjWp4AfviikBdQyJRKAjy0n3qGmpU5SoCdQ2JVKQgyMsMqGuoUY06RqDjCESiUBDkpfs1z1CjGi0IMjqOQCQKBUFeuk8VQaPKjxEUT0WtriGRSBQEeWl1DTUsdQ2JjIuCAMBdFUEjG95rqNRgsbqGRCpREED4AeIKgkZVqiJwh5zWIxCJQkEABauTaffRhlSqIsimg1NVBCIVKQigYHUyHVDWkEpVBNmh4FRjBCIVKQhAC9c3urYSB5QpCEQiUxBAQRBojKAhla0I1DUkUkmsQWBmS8xsjZmtM7PLS9x+kZltNbMnw5+/ibM9o1IQNLZkibmGVBGIRFb1egRRmVkSuAZ4F9ADPGZmy9x9VdGmP3H3S+JqRyRauL6xJRLBB/6IIMgPFisIRCqJsyJYDKxz9xfcfQi4CTg3xucbu/wHiIKgcaU6S48RpBQEIpXEGQRzgPUFl3vC64p9wMyeMrNbzOzQUg9kZkvNbIWZrdi6dWvtW5qvCDTXUONKdahrSGSM6j1Y/HNgnrsfB9wFXF9qI3e/1t0XufuiWbNm1b4VGiNofPtUBOoaEokqziDYABR+w58bXjfM3be5e/6/93vAm2Nsz+i0+2jjG7Ui0F5DIpXEGQSPAQvMbL6ZtQPnA8sKNzCz2QUXzwGejbE9oxsOAh1Q1rBSXSMrgvx5VQQiFcW215C7Z8zsEuAOIAlc5+4rzewqYIW7LwM+bmbnABlgO3BRXO0pSxVB40t17H0fQV1DIlWILQgA3H05sLzouisLzl8BXBFnGyLJ9EMipW6ERjbaXkN6T0Uqqvdg8YFBq5M1Pu01JDJmCgLQWgTNQHsNiYyZggC0OlkzUEUgMmYKAlBF0AxGHSNQEIhUoiCAYIxAQdDY2jpHmWtIg8UilSgIIPgA0a6jjS3VWbT7qI4jEIlKQQBB15BWJ2tsnVNhqBeymeCyuoZEIlMQgLqGmkHXtOB0YGdwqq4hkcgUBBAGgbqGGtqE6cFp3/bgNDsEiTYwq1+bRBqEggDCIFDXUEPrmhqc9u8ITrPpYJdSEalIQQCqCJpBvmtoOAiG1C0kEpGCAIK5hjRG0Ni6wq6h/oKuIQ0Ui0SiIMhmgg8NzTXU2IorgoyCQCQqBUFGq5M1hY7JYAl1DYmMgYIgrYXrm0IiEVQFfeoaEqmWgiC/cL2CoPF1TRu515AqApFIFAQZVQRNY0QQDEFSu4+KRKEgGK4ItPtow+uarr2GRMZAQZCfqExzDTU+dQ2JjEmsQWBmS8xsjZmtM7PLy2z3ATNzM1sUZ3tK0sL1zaNrGvQVdg2pIhCJIrYgMLMkcA1wJrAQuMDMFpbYrhu4DHgkrraUNdgbnLZPrMvTSw1NmB7OQJpWEIhUIc6KYDGwzt1fcPch4Cbg3BLbfQn4Z2CgxG3x270lOJ10cF2eXmpo+KCynTqOQKQKcQbBHGB9weWe8LphZnYicKi7317ugcxsqZmtMLMVW7durW0rezdBIgUTZtT2cWX/Gw6C7aoIRKpQt8FiM0sAVwOfrLStu1/r7ovcfdGsWbNq25DezTDpdcEBSdLYCqeZyKYVBCIRxfnptwE4tODy3PC6vG7gGOA+M3sJOBlYtt8HjHs3Qffr9utTSkxGBMEQpBQEIlHEGQSPAQvMbL6ZtQPnA8vyN7r7Lnef6e7z3H0e8DBwjruviLFN++rdrCBoFvkg6FPXkEg1YgsCd88AlwB3AM8CN7v7SjO7yszOiet5q7ZbQdA08quUDXcNabBYJIpUnA/u7suB5UXXXTnKtqfG2ZaS0gPBh4aCoDl0TAZLarBYpEqtPUK6e3Nw2j27vu2Q2jALDyrbBrmMgkAkotYOgt58EKgiaBpd0/YeG6KuIZFIWjwINgWnqgiaR9e0vQGvikAkkhYPgvADY5IqgqYxYXpBRaAgEIlCQZBo27u3iTS+rmmw+5XgvIJAJBIFQffsYJBRmkPXNMilg/MKApFIWjwIdFRx0+kqqO4UBCKRtHgQ6GCyptM1de957TUkEomCQEHQXPLTTIAqApGIWjcIhvpgcJeCoNlMUNeQSLVaNwh0VHFzGlERqGtIJIrWDQIdVdycCoMg1VG/dog0kBYOAh1V3JRG7DWkikAkihYOgvxRxVqruKl0dAczkILGCEQiauEg2ATJjpFdCdL48jOQgoJAJKIWDoJXgvEBHVXcfPJ7DqlrSCSSFg6CTRofaFaqCESq0sJBoIPJmpaCQKQqCgJpPl3qGhKpRqxBYGZLzGyNma0zs8tL3P63Zva0mT1pZg+a2cI42zNssBeGehUEzWq4ItBxBCJRxBYEZpYErgHOBBYCF5T4oL/B3Y919+OB/wNcHVd7RugN56vXGEFzmvH6IAx0QJlIJHFWBIuBde7+grsPATcB5xZu4O6vFVycCHiM7dlrt44qbmonXgQffwISyXq3RKQhpGJ87DnA+oLLPcBJxRuZ2cXA/wTagXeWeiAzWwosBTjssMPG1prHfwgPfTM4P9gbnGqJyuaUTOn4EJEq1H2w2N2vcfcjgM8Anx1lm2vdfZG7L5o1a9bYnmjCdJh1VPAzdxG85cMwc8HYGy4i0iTirAg2AIcWXJ4bXjeam4Bvx9aao88OfkREZIQ4K4LHgAVmNt/M2oHzgWWFG5hZ4Vfys4G1MbZHRERKiK0icPeMmV0C3AEkgevcfaWZXQWscPdlwCVmdgaQBnYAH4qrPSIiUlqcXUO4+3JgedF1VxacvyzO5xcRkcrqPlgsIiL1pSAQEWlxCgIRkRanIBARaXEKAhGRFmfu+2d6n1oxs63Ay2O8+0zg1Ro2p1G04utuxdcMrfm6W/E1Q/Wv+3B3Lzk1Q8MFwXiY2Qp3X1Tvduxvrfi6W/E1Q2u+7lZ8zVDb162uIRGRFqcgEBFpca0WBNfWuwF10oqvuxVfM7Tm627F1ww1fN0tNUYgIiL7arWKQEREiigIRERaXMsEgZktMbM1ZrbOzC6vd3viYGaHmtm9ZrbKzFaa2WXh9dPN7C4zWxueNt06jmaWNLMnzOwX4eX5ZvZI+H7/JFwTo6mY2VQzu8XMVpvZs2b21hZ5r/8u/Pt+xsxuNLPOZnu/zew6M9tiZs8UXFfyvbXA18PX/pSZnVjt87VEEJhZErgGOBNYCFxgZgvr26pYZIBPuvtC4GTg4vB1Xg7c4+4LgHvCy83mMuDZgsv/DPyLu7+BYK2Lv65Lq+L1NeBX7n408AcEr7+p32szmwN8HFjk7scQrHVyPs33fv87sKToutHe2zOBBeHPUsaw0mNLBAGwGFjn7i+4+xDBspjn1rlNNefum9z98fB8L8EHwxyC13p9uNn1wHvr08J4mNlcghXuvhdeNuCdwC3hJs34mqcA/wP4NwB3H3L3nTT5ex1KAV1mlgImAJtosvfb3R8AthddPdp7ey7wAw88DEw1s9nVPF+rBMEcYH3B5Z7wuqZlZvOAE4BHgIPdfVN402bg4Do1Ky5fBf4eyIWXZwA73T0TXm7G93s+sBX4ftgl9j0zm0iTv9fuvgH4CvB7ggDYBfyW5n+/YfT3dtyfb60SBC3FzCYB/wl8wt1fK7zNg/2Fm2afYTP7I2CLu/+23m3Zz1LAicC33f0EYA9F3UDN9l4DhP3i5xIE4SHARPbtQml6tX5vWyUINgCHFlyeG17XdMysjSAEfuzut4ZXv5IvFcPTLfVqXwzeDpxjZi8RdPm9k6DvfGrYdQDN+X73AD3u/kh4+RaCYGjm9xrgDOBFd9/q7mngVoK/gWZ/v2H093bcn2+tEgSPAQvCPQvaCQaXltW5TTUX9o3/G/Csu19dcNMy4EPh+Q8BP9vfbYuLu1/h7nPdfR7B+/prd/9z4F7gj8PNmuo1A7j7ZmC9mR0VXnU6sIomfq9DvwdONrMJ4d97/nU39fsdGu29XQb8Rbj30MnAroIupGjcvSV+gLOA54Dngf9V7/bE9BpPISgXnwKeDH/OIugzvwdYC9wNTK93W2N6/acCvwjPvx54FFgH/AfQUe/2xfB6jwdWhO/3bcC0VnivgS8Cq4FngB8CHc32fgM3EoyBpAmqv78e7b0FjGCvyOeBpwn2qKrq+TTFhIhIi2uVriERERmFgkBEpMUpCEREWpyCQESkxSkIRERanIJAZD8ys1PzM6SKHCgUBCIiLU5BIFKCmV1oZo+a2ZNm9t1wvYPdZvYv4Vz495jZrHDb483s4XAu+J8WzBP/BjO728x+Z2aPm9kR4cNPKlhH4MfhEbIidaMgECliZm8E/hR4u7sfD2SBPyeY4GyFu78JuB/4fHiXHwCfcffjCI7szF//Y+Aad/8D4G0ER4pCMCvsJwjWxng9wVw5InWTqryJSMs5HXgz8Fj4Zb2LYIKvHPCTcJsfAbeG6wJMdff7w+uvB/7DzLqBOe7+UwB3HwAIH+9Rd+8JLz8JzAMejP9liZSmIBDZlwHXu/sVI640+1zRdmOdn2Ww4HwW/R9KnalrSGRf9wB/bGYHwfBasYcT/L/kZ7j8M+BBd98F7DCzPwyv/yBwvwcrxPWY2XvDx+gwswn79VWIRKRvIiJF3H2VmX0WuNPMEgQzQF5MsPjL4vC2LQTjCBBMCfyd8IP+BeAvw+s/CHzXzK4KH+NP9uPLEIlMs4+KRGRmu919Ur3bIVJr6hoSEWlxqghERFqcKgIRkRanIBARaXEKAhGRFqcgEBFpcQoCEZEW9/8D1EVXIPMLfUkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
