{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 16 13:26:00 2019\n",
    "\n",
    "@author: tealeeseng\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; # for GPU 1.\n",
    "import pathlib\n",
    "# import warnings\n",
    "import random\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "pixel = 128\n",
    "batch_size = 128\n",
    "epoch_size = 100\n",
    "\n",
    "datatype = 'data-face'\n",
    "modelname = 'model/face_resnet_sample_b'+str(batch_size)+'_e'+str(epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resLyr(inputs,\n",
    "           numFilters=16,\n",
    "           kernelSize=3,\n",
    "           strides=1,\n",
    "           activation='relu',\n",
    "           batchNorm=True,\n",
    "           convFirst=True,\n",
    "           lyrName=None):\n",
    "    convLyr = Conv2D(numFilters,\n",
    "                     kernel_size=kernelSize,\n",
    "                     strides=strides,\n",
    "                     padding='same',\n",
    "                     kernel_initializer='he_normal',\n",
    "                     kernel_regularizer=l2(1e-4),\n",
    "                     name=lyrName + '_conv' if lyrName else None)\n",
    "\n",
    "    x = inputs\n",
    "    if convFirst:\n",
    "        x = convLyr(x)\n",
    "        if batchNorm:\n",
    "            x = BatchNormalization(name=lyrName + '_bn' if lyrName else None)(x)\n",
    "\n",
    "        if activation is not None:\n",
    "            x = Activation(activation, name=lyrName + '_' + activation if lyrName else None)(x)\n",
    "    else:\n",
    "        if batchNorm:\n",
    "            x = BatchNormalization(name=lyrName + '_bn' if lyrName else None)(x)\n",
    "\n",
    "        if activation is not None:\n",
    "            x = Activation(activation, name=lyrName + '_' + activation if lyrName else None)(x)\n",
    "        x = convLyr(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resBlkV1(inputs,\n",
    "             numFilters=16,\n",
    "             numBlocks=4,\n",
    "             downSampleOnFirst=True,\n",
    "             names=None):\n",
    "    x = inputs\n",
    "    for run in range(0, numBlocks):\n",
    "        strides = 1\n",
    "        blkStr = str(run + 1)\n",
    "        if downSampleOnFirst and run == 0:\n",
    "            strides = 2\n",
    "\n",
    "        y = resLyr(inputs=x,\n",
    "                   numFilters=numFilters,\n",
    "                   strides=strides,\n",
    "                   lyrName=names + '_Blk' + blkStr + '_Res1' if names else None)\n",
    "        y = resLyr(inputs=y,\n",
    "                   numFilters=numFilters,\n",
    "                   activation=None,\n",
    "                   lyrName=names + '_Blk' + blkStr + '_Res2' if names else None)\n",
    "\n",
    "        if downSampleOnFirst and run == 0:\n",
    "            x = resLyr(inputs=x,\n",
    "                       numFilters=numFilters,\n",
    "                       kernelSize=1,\n",
    "                       strides=strides,\n",
    "                       activation=None,\n",
    "                       batchNorm=False,\n",
    "                       lyrName=names + '_Blk' + blkStr + '_lin' if names else None)\n",
    "\n",
    "        x = add([x, y],\n",
    "                name=names + '_Blk' + blkStr + '_add' if names else None)\n",
    "\n",
    "        x = Activation('relu', name=names + '_Blk' + blkStr + '_relu' if names else None)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createResNetV1(inputShape=(128, 128, 3),\n",
    "                   numberClasses=3):\n",
    "    inputs = Input(shape=inputShape)\n",
    "    v = resLyr(inputs, numFilters=16, kernelSize=5, lyrName='Inpt')\n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=16,\n",
    "                 numBlocks=5,\n",
    "                 downSampleOnFirst=False,\n",
    "                 names='Stg1')\n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=32,\n",
    "                 numBlocks=5,\n",
    "                 downSampleOnFirst=True,\n",
    "                 names='Stg2')\n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=64,\n",
    "                 numBlocks=5,\n",
    "                 downSampleOnFirst=True,\n",
    "                 names='Stg3')\n",
    "#     v = resBlkV1(inputs=v,\n",
    "#                  numFilters=512,\n",
    "#                  numBlocks=6,\n",
    "#                  downSampleOnFirst=True,\n",
    "#                  names='Stg4')\n",
    "    v = AveragePooling2D(pool_size=8,\n",
    "                         name='AvgPool')(v)\n",
    "    v = Flatten()(v)\n",
    "    outputs = Dense(numberClasses,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(v)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.Adam(lr=0.002),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "    # parallel = multi_gpu_model(model, gpus=2)\n",
    "    #\n",
    "    # parallel.compile(loss='categorical_crossentropy',\n",
    "    #          optimizer = optimizers.Adam(lr=0.001),\n",
    "    #          metrics=['accuracy'])\n",
    "    #\n",
    "    # return parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(target_size=(128, 128)):\n",
    "    model = createResNetV1(inputShape=(target_size[0], target_size[1], 3))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the models\n",
    "def printSample(all_image_paths):\n",
    "    img_path = all_image_paths[0]\n",
    "    image_path = img_path\n",
    "    img_raw = tf.io.read_file(img_path)\n",
    "    # print(repr(img_raw)[:100]+' ...')\n",
    "    img_tensor = tf.image.decode_png(img_raw, channels=3)\n",
    "    img_tensor = tf.image.resize_image_with_crop_or_pad(img_tensor, 128, 128)\n",
    "    print(img_tensor.shape, ' ', img_tensor.dtype)\n",
    "    # for n in range(3):\n",
    "    #     image_path = random.choice(all_image_paths)\n",
    "    img = mpimg.imread(image_path)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n",
    "    # display.display(display.Image(image_path))\n",
    "    # print(caption_image(image_path))\n",
    "    # print(matplotlib.get_backend())\n",
    "    img_final = tf.image.resize(img_tensor, [128, 128])\n",
    "    img_final = tf.cast(img_final, tf.float32)\n",
    "    img_final = img_final / 255.0\n",
    "    print(img_final.shape, ' ', img_final.numpy().min(), ' ', img_final.numpy().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrSchedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 160:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 140:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "\n",
    "    print('Learning rate:', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (pixel, pixel)\n",
    "seed = 29\n",
    "\n",
    "\n",
    "tdf = pd.read_csv(datatype+\"_train_set.csv\")\n",
    "vdf = pd.read_csv(datatype+\"_v_set.csv\")\n",
    "\n",
    "# import cv2\n",
    "# # img = cv2.imread('./data-face/XiaoYan/IMG_4749.MOV-482.jpg')\n",
    "# # print(img)\n",
    "\n",
    "# x_train = []\n",
    "# for i in range(len(tdf.index)):\n",
    "#     imgfile = \"./\"+tdf.iloc[i]['filename']\n",
    "#     img = cv2.imread(imgfile)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     x_train.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_conv (Conv2D)              (None, 128, 128, 16) 1216        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_bn (BatchNormalization)    (None, 128, 128, 16) 64          Inpt_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_relu (Activation)          (None, 128, 128, 16) 0           Inpt_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Inpt_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_add (Add)             (None, 128, 128, 16) 0           Inpt_relu[0][0]                  \n",
      "                                                                 Stg1_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_add (Add)             (None, 128, 128, 16) 0           Stg1_Blk1_relu[0][0]             \n",
      "                                                                 Stg1_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_add (Add)             (None, 128, 128, 16) 0           Stg1_Blk2_relu[0][0]             \n",
      "                                                                 Stg1_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk4_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk4_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk4_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk4_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_add (Add)             (None, 128, 128, 16) 0           Stg1_Blk3_relu[0][0]             \n",
      "                                                                 Stg1_Blk4_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk4_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk5_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk5_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk5_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk5_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_add (Add)             (None, 128, 128, 16) 0           Stg1_Blk4_relu[0][0]             \n",
      "                                                                 Stg1_Blk5_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk5_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_conv (Conv2D)    (None, 64, 64, 32)   4640        Stg1_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_lin_conv (Conv2D)     (None, 64, 64, 32)   544         Stg1_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg2_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk1_relu[0][0]             \n",
      "                                                                 Stg2_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk2_relu[0][0]             \n",
      "                                                                 Stg2_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk4_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk4_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk4_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk4_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk3_relu[0][0]             \n",
      "                                                                 Stg2_Blk4_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk4_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk5_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk5_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk5_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk5_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk4_relu[0][0]             \n",
      "                                                                 Stg2_Blk5_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk5_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_conv (Conv2D)    (None, 32, 32, 64)   18496       Stg2_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_lin_conv (Conv2D)     (None, 32, 32, 64)   2112        Stg2_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg3_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk1_relu[0][0]             \n",
      "                                                                 Stg3_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk2_relu[0][0]             \n",
      "                                                                 Stg3_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk4_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk4_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk4_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk4_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk3_relu[0][0]             \n",
      "                                                                 Stg3_Blk4_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk4_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk5_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk5_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk5_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk5_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk4_relu[0][0]             \n",
      "                                                                 Stg3_Blk5_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk5_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "AvgPool (AveragePooling2D)      (None, 4, 4, 64)     0           Stg3_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           AvgPool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            3075        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 473,411\n",
      "Trainable params: 471,139\n",
      "Non-trainable params: 2,272\n",
      "__________________________________________________________________________________________________\n",
      "model summary: None\n",
      "Found 3738 validated image filenames belonging to 3 classes.\n",
      "Found 1051 validated image filenames belonging to 3 classes.\n",
      "      Unnamed: 0                                           filename    label\n",
      "0              1             data-face/XiaoYan/IMG_4749.MOV-482.jpg  XiaoYan\n",
      "1              2             data-face/XiaoYan/IMG_4705.MOV-732.jpg  XiaoYan\n",
      "2              4  data-face/LeeSeng/VID_20190908_145635.mp4-1233...  LeeSeng\n",
      "3              5  data-face/LeeSeng/VID_20190908_145635.mp4-1399...  LeeSeng\n",
      "4             10      data-face/GabyNg/20190902_124535.mp4-1265.jpg   GabyNg\n",
      "...          ...                                                ...      ...\n",
      "3733        5343            data-face/XiaoYan/IMG_4749.MOV-1701.jpg  XiaoYan\n",
      "3734        5344             data-face/XiaoYan/IMG_4749.MOV-179.jpg  XiaoYan\n",
      "3735        5345             data-face/XiaoYan/IMG_4749.MOV-916.jpg  XiaoYan\n",
      "3736        5347             data-face/XiaoYan/IMG_4747.MOV-251.jpg  XiaoYan\n",
      "3737        5348      data-face/GabyNg/20190902_124535.mp4-1459.jpg   GabyNg\n",
      "\n",
      "[3738 rows x 3 columns]\n",
      "      Unnamed: 0                                           filename    label\n",
      "0              0  data-face/LeeSeng/VID_20190908_145635.mp4-607.jpg  LeeSeng\n",
      "1              3            data-face/XiaoYan/IMG_4749.MOV-2097.jpg  XiaoYan\n",
      "2              6             data-face/XiaoYan/IMG_4747.MOV-296.jpg  XiaoYan\n",
      "3              7            data-face/XiaoYan/IMG_4749.MOV-1992.jpg  XiaoYan\n",
      "4              8       data-face/GabyNg/20190902_124535.mp4-955.jpg   GabyNg\n",
      "...          ...                                                ...      ...\n",
      "1046        5325  data-face/LeeSeng/VID_20190902_091449.mp4-969.jpg  LeeSeng\n",
      "1047        5329  data-face/LeeSeng/VID_20190908_145635.mp4-222.jpg  LeeSeng\n",
      "1048        5334             data-face/XiaoYan/IMG_4749.MOV-537.jpg  XiaoYan\n",
      "1049        5336            data-face/XiaoYan/IMG_4749.MOV-1348.jpg  XiaoYan\n",
      "1050        5346            data-face/XiaoYan/IMG_4747.MOV-1002.jpg  XiaoYan\n",
      "\n",
      "[1051 rows x 3 columns]\n",
      "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator object at 0x7f9c2b52c898>\n",
      "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator object at 0x7f9c2bb37ef0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 38s 1s/step - loss: 0.7171 - acc: 0.8798 - val_loss: 62.3213 - val_acc: 0.3145\n",
      "Learning rate: 0.001\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 28s 970ms/step - loss: 0.2600 - acc: 0.9958 - val_loss: 8.8589 - val_acc: 0.3135\n",
      "Learning rate: 0.001\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 28s 981ms/step - loss: 0.2508 - acc: 0.9986 - val_loss: 2.2888 - val_acc: 0.5430\n",
      "Learning rate: 0.001\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 28s 974ms/step - loss: 0.2457 - acc: 0.9994 - val_loss: 0.4463 - val_acc: 0.9209\n",
      "Learning rate: 0.001\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 28s 975ms/step - loss: 0.2418 - acc: 0.9997 - val_loss: 0.2408 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 28s 979ms/step - loss: 0.2389 - acc: 0.9995 - val_loss: 0.2358 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 28s 968ms/step - loss: 0.2346 - acc: 1.0000 - val_loss: 0.2326 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 27s 944ms/step - loss: 0.2319 - acc: 0.9997 - val_loss: 0.2684 - val_acc: 0.9883\n",
      "Learning rate: 0.001\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 27s 945ms/step - loss: 0.2370 - acc: 0.9989 - val_loss: 0.2687 - val_acc: 0.9873\n",
      "Learning rate: 0.001\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 28s 959ms/step - loss: 0.2397 - acc: 0.9958 - val_loss: 0.2374 - val_acc: 0.9941\n",
      "Learning rate: 0.001\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 27s 942ms/step - loss: 0.2284 - acc: 0.9983 - val_loss: 0.4550 - val_acc: 0.9111\n",
      "Learning rate: 0.001\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 27s 932ms/step - loss: 0.2228 - acc: 0.9989 - val_loss: 0.2264 - val_acc: 0.9980\n",
      "Learning rate: 0.001\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 27s 929ms/step - loss: 0.2181 - acc: 0.9989 - val_loss: 0.2188 - val_acc: 0.9990\n",
      "Learning rate: 0.001\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 27s 942ms/step - loss: 0.2134 - acc: 0.9997 - val_loss: 0.2156 - val_acc: 0.9990\n",
      "Learning rate: 0.001\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 26s 903ms/step - loss: 0.2097 - acc: 0.9997 - val_loss: 0.2078 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 26s 902ms/step - loss: 0.2061 - acc: 1.0000 - val_loss: 0.2042 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 27s 918ms/step - loss: 0.2062 - acc: 0.9981 - val_loss: 0.2009 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 26s 903ms/step - loss: 0.2071 - acc: 0.9964 - val_loss: 2.6297 - val_acc: 0.7070\n",
      "Learning rate: 0.001\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 26s 898ms/step - loss: 0.2025 - acc: 0.9978 - val_loss: 0.1986 - val_acc: 0.9980\n",
      "Learning rate: 0.001\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 26s 906ms/step - loss: 0.1942 - acc: 0.9997 - val_loss: 0.1933 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 26s 886ms/step - loss: 0.1902 - acc: 1.0000 - val_loss: 0.1885 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 26s 882ms/step - loss: 0.1869 - acc: 1.0000 - val_loss: 0.1851 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 25s 873ms/step - loss: 0.1837 - acc: 0.9997 - val_loss: 0.1818 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 25s 850ms/step - loss: 0.1803 - acc: 1.0000 - val_loss: 0.1785 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 26s 882ms/step - loss: 0.1775 - acc: 1.0000 - val_loss: 0.1752 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 25s 868ms/step - loss: 0.1740 - acc: 1.0000 - val_loss: 0.1834 - val_acc: 0.9971\n",
      "Learning rate: 0.001\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 25s 852ms/step - loss: 0.1707 - acc: 1.0000 - val_loss: 0.1691 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 25s 848ms/step - loss: 0.1674 - acc: 1.0000 - val_loss: 0.1656 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 24s 841ms/step - loss: 0.1641 - acc: 1.0000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 24s 835ms/step - loss: 0.1611 - acc: 1.0000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 24s 814ms/step - loss: 0.1579 - acc: 1.0000 - val_loss: 0.1562 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 28s 981ms/step - loss: 0.1548 - acc: 1.0000 - val_loss: 0.1532 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 28s 978ms/step - loss: 0.1518 - acc: 1.0000 - val_loss: 0.1502 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 28s 968ms/step - loss: 0.1487 - acc: 1.0000 - val_loss: 0.1472 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 29s 991ms/step - loss: 0.1458 - acc: 1.0000 - val_loss: 0.1442 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 28s 951ms/step - loss: 0.1428 - acc: 1.0000 - val_loss: 0.1413 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 28s 953ms/step - loss: 0.1400 - acc: 1.0000 - val_loss: 0.1385 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 28s 950ms/step - loss: 0.1371 - acc: 1.0000 - val_loss: 0.1357 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 28s 949ms/step - loss: 0.1343 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 28s 951ms/step - loss: 0.1316 - acc: 1.0000 - val_loss: 0.1301 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 27s 936ms/step - loss: 0.1289 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 27s 935ms/step - loss: 0.1266 - acc: 1.0000 - val_loss: 0.1259 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 28s 949ms/step - loss: 0.1237 - acc: 1.0000 - val_loss: 0.1223 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 26s 897ms/step - loss: 0.1211 - acc: 1.0000 - val_loss: 0.1197 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 27s 916ms/step - loss: 0.1185 - acc: 1.0000 - val_loss: 0.1172 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 27s 932ms/step - loss: 0.1160 - acc: 1.0000 - val_loss: 0.1147 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 26s 909ms/step - loss: 0.1136 - acc: 1.0000 - val_loss: 0.1123 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 26s 899ms/step - loss: 0.1112 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 26s 896ms/step - loss: 0.1090 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 25s 871ms/step - loss: 0.1066 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 26s 880ms/step - loss: 0.1043 - acc: 1.0000 - val_loss: 0.1031 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 26s 898ms/step - loss: 0.1020 - acc: 1.0000 - val_loss: 0.1009 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 25s 855ms/step - loss: 0.0998 - acc: 1.0000 - val_loss: 0.0987 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 26s 883ms/step - loss: 0.0977 - acc: 1.0000 - val_loss: 0.0966 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 25s 863ms/step - loss: 0.0956 - acc: 1.0000 - val_loss: 0.0945 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 24s 835ms/step - loss: 0.0935 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 25s 867ms/step - loss: 0.0915 - acc: 1.0000 - val_loss: 0.0905 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 24s 840ms/step - loss: 0.0895 - acc: 1.0000 - val_loss: 0.0885 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 24s 842ms/step - loss: 0.0876 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 24s 830ms/step - loss: 0.0857 - acc: 1.0000 - val_loss: 0.0847 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 24s 815ms/step - loss: 0.0838 - acc: 1.0000 - val_loss: 0.0829 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 28s 978ms/step - loss: 0.0820 - acc: 1.0000 - val_loss: 0.0811 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 28s 972ms/step - loss: 0.0803 - acc: 1.0000 - val_loss: 0.0794 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 28s 982ms/step - loss: 0.0851 - acc: 0.9987 - val_loss: 4.5046 - val_acc: 0.7012\n",
      "Learning rate: 0.001\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 28s 973ms/step - loss: 0.5067 - acc: 0.9239 - val_loss: 126625.1260 - val_acc: 0.2939\n",
      "Learning rate: 0.001\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 28s 970ms/step - loss: 0.1187 - acc: 0.9953 - val_loss: 1347.6651 - val_acc: 0.2939\n",
      "Learning rate: 0.001\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 28s 949ms/step - loss: 0.1093 - acc: 0.9992 - val_loss: 148.6317 - val_acc: 0.2939\n",
      "Learning rate: 0.001\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 28s 974ms/step - loss: 0.1072 - acc: 0.9981 - val_loss: 47.7712 - val_acc: 0.2939\n",
      "Learning rate: 0.001\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 27s 930ms/step - loss: 0.1031 - acc: 0.9997 - val_loss: 14.5355 - val_acc: 0.3018\n",
      "Learning rate: 0.001\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 28s 965ms/step - loss: 0.1022 - acc: 0.9997 - val_loss: 2.5601 - val_acc: 0.6221\n",
      "Learning rate: 0.001\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 27s 945ms/step - loss: 0.1016 - acc: 0.9992 - val_loss: 0.1543 - val_acc: 0.9795\n",
      "Learning rate: 0.001\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 27s 943ms/step - loss: 0.0991 - acc: 0.9994 - val_loss: 0.1023 - val_acc: 0.9971\n",
      "Learning rate: 0.001\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 27s 932ms/step - loss: 0.0966 - acc: 1.0000 - val_loss: 0.0956 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 27s 914ms/step - loss: 0.0973 - acc: 0.9991 - val_loss: 0.0946 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 27s 919ms/step - loss: 0.0946 - acc: 0.9997 - val_loss: 0.0949 - val_acc: 0.9990\n",
      "Learning rate: 0.001\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 26s 914ms/step - loss: 0.0943 - acc: 0.9994 - val_loss: 0.0918 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 27s 927ms/step - loss: 0.0926 - acc: 0.9995 - val_loss: 0.0905 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 26s 908ms/step - loss: 0.0929 - acc: 0.9989 - val_loss: 0.0904 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 25s 876ms/step - loss: 0.0932 - acc: 0.9991 - val_loss: 0.0881 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 26s 890ms/step - loss: 0.0882 - acc: 0.9997 - val_loss: 0.0869 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 26s 883ms/step - loss: 0.0868 - acc: 1.0000 - val_loss: 0.0858 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 26s 898ms/step - loss: 0.0879 - acc: 0.9992 - val_loss: 0.0857 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 25s 872ms/step - loss: 0.0860 - acc: 1.0000 - val_loss: 0.0855 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 25s 865ms/step - loss: 0.0859 - acc: 1.0000 - val_loss: 0.0854 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 25s 864ms/step - loss: 0.0857 - acc: 1.0000 - val_loss: 0.0853 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 24s 837ms/step - loss: 0.0858 - acc: 0.9997 - val_loss: 0.0852 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 25s 870ms/step - loss: 0.0857 - acc: 0.9997 - val_loss: 0.0850 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 25s 845ms/step - loss: 0.0852 - acc: 1.0000 - val_loss: 0.0849 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 24s 842ms/step - loss: 0.0854 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 24s 834ms/step - loss: 0.0851 - acc: 1.0000 - val_loss: 0.0847 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 24s 813ms/step - loss: 0.0847 - acc: 1.0000 - val_loss: 0.0845 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 28s 976ms/step - loss: 0.0850 - acc: 0.9997 - val_loss: 0.0844 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 28s 976ms/step - loss: 0.0845 - acc: 1.0000 - val_loss: 0.0843 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 28s 958ms/step - loss: 0.0851 - acc: 0.9997 - val_loss: 0.0841 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 28s 963ms/step - loss: 0.0842 - acc: 1.0000 - val_loss: 0.0840 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 28s 968ms/step - loss: 0.0841 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 28s 959ms/step - loss: 0.0841 - acc: 1.0000 - val_loss: 0.0837 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 28s 956ms/step - loss: 0.0856 - acc: 0.9997 - val_loss: 0.0836 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 28s 950ms/step - loss: 0.0849 - acc: 0.9997 - val_loss: 0.0834 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 28s 965ms/step - loss: 0.0839 - acc: 0.9997 - val_loss: 0.0833 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = createModel(target_size)\n",
    "print('model summary:', model.summary())\n",
    "\n",
    "filepath = modelname + \".hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=0,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "# Log the epoch detail into csv\n",
    "csv_logger = CSVLogger(modelname + '.csv')\n",
    "# callbacks_list  = [checkpoint,csv_logger]\n",
    "\n",
    "LRScheduler = LearningRateScheduler(lrSchedule)\n",
    "callbacks_list = [checkpoint, csv_logger, LRScheduler]\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.10,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "vdatagen = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    rotation_range=0,\n",
    "    zoom_range=0,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=tdf, x_col=\"filename\", y_col=\"label\",\n",
    "                                              class_mode=\"categorical\", target_size=target_size,\n",
    "                                              shuffle=True,\n",
    "                                              batch_size=batch_size)\n",
    "\n",
    "valid_generator = vdatagen.flow_from_dataframe(dataframe=vdf, x_col=\"filename\", y_col=\"label\",\n",
    "                                               class_mode=\"categorical\", target_size=target_size,\n",
    "                                               shuffle=True,\n",
    "                                               batch_size=batch_size)\n",
    "print(tdf)\n",
    "print(vdf)\n",
    "print(train_generator)\n",
    "print(valid_generator)\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "\n",
    "# Change from 100 to epochs as testing shows 50 epochs is sufficient to generate a validation accuracy of more than 85%\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    validation_data=valid_generator,\n",
    "                    epochs=epoch_size,\n",
    "                    verbose=1,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks=callbacks_list)\n",
    "# ......................................................................\n",
    "\n",
    "# Now the training is complete, we get\n",
    "# another object to load the weights\n",
    "# compile it, so that we can do\n",
    "# final evaluation on it\n",
    "# modelGo.load_weights(filepath)\n",
    "# modelGo.compile(loss='categorical_crossentropy',\n",
    "#                 optimizer=optimizers.Adam(lr=0.001),\n",
    "#                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(modelname + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
