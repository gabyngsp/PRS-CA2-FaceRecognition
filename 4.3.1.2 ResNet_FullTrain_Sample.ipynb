{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 16 13:26:00 2019\n",
    "\n",
    "@author: tealeeseng\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; # for GPU 1.\n",
    "import pathlib\n",
    "# import warnings\n",
    "import random\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "pixel = 128\n",
    "batch_size = 128\n",
    "epoch_size = 100\n",
    "\n",
    "datatype = 'data-full'\n",
    "modelname = f'model/full_resnet_sample_b{str(batch_size)}_e{str(epoch_size)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resLyr(inputs,\n",
    "           numFilters=16,\n",
    "           kernelSize=3,\n",
    "           strides=1,\n",
    "           activation='relu',\n",
    "           batchNorm=True,\n",
    "           convFirst=True,\n",
    "           lyrName=None):\n",
    "    convLyr = Conv2D(numFilters,\n",
    "                     kernel_size=kernelSize,\n",
    "                     strides=strides,\n",
    "                     padding='same',\n",
    "                     kernel_initializer='he_normal',\n",
    "                     kernel_regularizer=l2(1e-4),\n",
    "                     name=lyrName + '_conv' if lyrName else None)\n",
    "\n",
    "    x = inputs\n",
    "    if convFirst:\n",
    "        x = convLyr(x)\n",
    "        if batchNorm:\n",
    "            x = BatchNormalization(name=lyrName + '_bn' if lyrName else None)(x)\n",
    "\n",
    "        if activation is not None:\n",
    "            x = Activation(activation, name=lyrName + '_' + activation if lyrName else None)(x)\n",
    "    else:\n",
    "        if batchNorm:\n",
    "            x = BatchNormalization(name=lyrName + '_bn' if lyrName else None)(x)\n",
    "\n",
    "        if activation is not None:\n",
    "            x = Activation(activation, name=lyrName + '_' + activation if lyrName else None)(x)\n",
    "        x = convLyr(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resBlkV1(inputs,\n",
    "             numFilters=16,\n",
    "             numBlocks=4,\n",
    "             downSampleOnFirst=True,\n",
    "             names=None):\n",
    "    x = inputs\n",
    "    for run in range(0, numBlocks):\n",
    "        strides = 1\n",
    "        blkStr = str(run + 1)\n",
    "        if downSampleOnFirst and run == 0:\n",
    "            strides = 2\n",
    "\n",
    "        y = resLyr(inputs=x,\n",
    "                   numFilters=numFilters,\n",
    "                   strides=strides,\n",
    "                   lyrName=names + '_Blk' + blkStr + '_Res1' if names else None)\n",
    "        y = resLyr(inputs=y,\n",
    "                   numFilters=numFilters,\n",
    "                   activation=None,\n",
    "                   lyrName=names + '_Blk' + blkStr + '_Res2' if names else None)\n",
    "\n",
    "        if downSampleOnFirst and run == 0:\n",
    "            x = resLyr(inputs=x,\n",
    "                       numFilters=numFilters,\n",
    "                       kernelSize=1,\n",
    "                       strides=strides,\n",
    "                       activation=None,\n",
    "                       batchNorm=False,\n",
    "                       lyrName=names + '_Blk' + blkStr + '_lin' if names else None)\n",
    "\n",
    "        x = add([x, y],\n",
    "                name=names + '_Blk' + blkStr + '_add' if names else None)\n",
    "\n",
    "        x = Activation('relu', name=names + '_Blk' + blkStr + '_relu' if names else None)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createResNetV1(inputShape=(128, 128, 3), numberClasses=3):\n",
    "    inputs = Input(shape=inputShape)\n",
    "    v = resLyr(inputs, numFilters=16, kernelSize=5, lyrName='Inpt')\n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=16,\n",
    "                 numBlocks=5,\n",
    "                 downSampleOnFirst=False,\n",
    "                 names='Stg1')\n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=32,\n",
    "                 numBlocks=5,\n",
    "                 downSampleOnFirst=True,\n",
    "                 names='Stg2')\n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=64,\n",
    "                 numBlocks=5,\n",
    "                 downSampleOnFirst=True,\n",
    "                 names='Stg3')\n",
    "\n",
    "    v = AveragePooling2D(pool_size=8,\n",
    "                         name='AvgPool')(v)\n",
    "    v = Flatten()(v)\n",
    "    outputs = Dense(numberClasses,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(v)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.Adam(lr=0.002),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(target_size=(128, 128)):\n",
    "    model = createResNetV1(inputShape=(target_size[0], target_size[1], 3))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the models\n",
    "def printSample(all_image_paths):\n",
    "    img_path = all_image_paths[0]\n",
    "    image_path = img_path\n",
    "    img_raw = tf.io.read_file(img_path)\n",
    "    # print(repr(img_raw)[:100]+' ...')\n",
    "    img_tensor = tf.image.decode_png(img_raw, channels=3)\n",
    "    img_tensor = tf.image.resize_image_with_crop_or_pad(img_tensor, 128, 128)\n",
    "    print(img_tensor.shape, ' ', img_tensor.dtype)\n",
    "    # for n in range(3):\n",
    "    #     image_path = random.choice(all_image_paths)\n",
    "    img = mpimg.imread(image_path)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n",
    "    # display.display(display.Image(image_path))\n",
    "    # print(caption_image(image_path))\n",
    "    # print(matplotlib.get_backend())\n",
    "    img_final = tf.image.resize(img_tensor, [128, 128])\n",
    "    img_final = tf.cast(img_final, tf.float32)\n",
    "    img_final = img_final / 255.0\n",
    "    print(img_final.shape, ' ', img_final.numpy().min(), ' ', img_final.numpy().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrSchedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 160:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 140:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "\n",
    "    print('Learning rate:', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (pixel, pixel)\n",
    "seed = 29\n",
    "\n",
    "\n",
    "tdf = pd.read_csv(datatype+\"_train_set.csv\")\n",
    "vdf = pd.read_csv(datatype+\"_v_set.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_conv (Conv2D)              (None, 128, 128, 16) 1216        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_bn (BatchNormalization)    (None, 128, 128, 16) 64          Inpt_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_relu (Activation)          (None, 128, 128, 16) 0           Inpt_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Inpt_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_add (Add)             (None, 128, 128, 16) 0           Inpt_relu[0][0]                  \n",
      "                                                                 Stg1_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_add (Add)             (None, 128, 128, 16) 0           Stg1_Blk1_relu[0][0]             \n",
      "                                                                 Stg1_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_add (Add)             (None, 128, 128, 16) 0           Stg1_Blk2_relu[0][0]             \n",
      "                                                                 Stg1_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk4_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk4_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk4_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk4_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_add (Add)             (None, 128, 128, 16) 0           Stg1_Blk3_relu[0][0]             \n",
      "                                                                 Stg1_Blk4_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk4_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk4_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res1_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res1_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk5_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res1_relu (Activation (None, 128, 128, 16) 0           Stg1_Blk5_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res2_conv (Conv2D)    (None, 128, 128, 16) 2320        Stg1_Blk5_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_Res2_bn (BatchNormali (None, 128, 128, 16) 64          Stg1_Blk5_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_add (Add)             (None, 128, 128, 16) 0           Stg1_Blk4_relu[0][0]             \n",
      "                                                                 Stg1_Blk5_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk5_relu (Activation)     (None, 128, 128, 16) 0           Stg1_Blk5_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_conv (Conv2D)    (None, 64, 64, 32)   4640        Stg1_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_lin_conv (Conv2D)     (None, 64, 64, 32)   544         Stg1_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg2_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk1_relu[0][0]             \n",
      "                                                                 Stg2_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk2_relu[0][0]             \n",
      "                                                                 Stg2_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk4_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk4_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk4_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk4_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk3_relu[0][0]             \n",
      "                                                                 Stg2_Blk4_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk4_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk4_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk5_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res1_relu (Activation (None, 64, 64, 32)   0           Stg2_Blk5_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res2_conv (Conv2D)    (None, 64, 64, 32)   9248        Stg2_Blk5_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_Res2_bn (BatchNormali (None, 64, 64, 32)   128         Stg2_Blk5_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_add (Add)             (None, 64, 64, 32)   0           Stg2_Blk4_relu[0][0]             \n",
      "                                                                 Stg2_Blk5_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk5_relu (Activation)     (None, 64, 64, 32)   0           Stg2_Blk5_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_conv (Conv2D)    (None, 32, 32, 64)   18496       Stg2_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_lin_conv (Conv2D)     (None, 32, 32, 64)   2112        Stg2_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg3_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk1_relu[0][0]             \n",
      "                                                                 Stg3_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk2_relu[0][0]             \n",
      "                                                                 Stg3_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk4_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk4_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk4_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk4_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk3_relu[0][0]             \n",
      "                                                                 Stg3_Blk4_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk4_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk4_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk5_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res1_relu (Activation (None, 32, 32, 64)   0           Stg3_Blk5_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res2_conv (Conv2D)    (None, 32, 32, 64)   36928       Stg3_Blk5_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_Res2_bn (BatchNormali (None, 32, 32, 64)   256         Stg3_Blk5_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_add (Add)             (None, 32, 32, 64)   0           Stg3_Blk4_relu[0][0]             \n",
      "                                                                 Stg3_Blk5_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk5_relu (Activation)     (None, 32, 32, 64)   0           Stg3_Blk5_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "AvgPool (AveragePooling2D)      (None, 4, 4, 64)     0           Stg3_Blk5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           AvgPool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            3075        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 473,411\n",
      "Trainable params: 471,139\n",
      "Non-trainable params: 2,272\n",
      "__________________________________________________________________________________________________\n",
      "model summary: None\n",
      "Found 4497 validated image filenames belonging to 3 classes.\n",
      "Found 1281 validated image filenames belonging to 3 classes.\n",
      "      Unnamed: 0                                           filename    label\n",
      "0              1      data-full/GabyNg/20190902_124535.mp4-1787.jpg   GabyNg\n",
      "1              2  data-full/LeeSeng/VID_20190905_204615.mp4-130.jpg  LeeSeng\n",
      "2              4            data-full/XiaoYan/IMG_4747.MOV-1267.jpg  XiaoYan\n",
      "3              5       data-full/GabyNg/20190902_124712.mp4-204.jpg   GabyNg\n",
      "4             10      data-full/GabyNg/20190902_124535.mp4-1773.jpg   GabyNg\n",
      "...          ...                                                ...      ...\n",
      "4492        6450             data-full/XiaoYan/IMG_4705.MOV-124.jpg  XiaoYan\n",
      "4493        6451              data-full/XiaoYan/IMG_4749.MOV-99.jpg  XiaoYan\n",
      "4494        6453       data-full/GabyNg/20190902_124535.mp4-883.jpg   GabyNg\n",
      "4495        6456             data-full/XiaoYan/IMG_4749.MOV-746.jpg  XiaoYan\n",
      "4496        6458            data-full/XiaoYan/IMG_4747.MOV-1291.jpg  XiaoYan\n",
      "\n",
      "[4497 rows x 3 columns]\n",
      "      Unnamed: 0                                           filename    label\n",
      "0              0  data-full/LeeSeng/VID_20190902_091449.mp4-940.jpg  LeeSeng\n",
      "1              3  data-full/LeeSeng/VID_20190902_091449.mp4-1030...  LeeSeng\n",
      "2              6      data-full/GabyNg/20190902_124535.mp4-1174.jpg   GabyNg\n",
      "3              7             data-full/XiaoYan/IMG_4749.MOV-304.jpg  XiaoYan\n",
      "4              8             data-full/XiaoYan/IMG_4749.MOV-328.jpg  XiaoYan\n",
      "...          ...                                                ...      ...\n",
      "1276        6439             data-full/XiaoYan/IMG_4705.MOV-188.jpg  XiaoYan\n",
      "1277        6441      data-full/GabyNg/20190902_124712.mp4-1109.jpg   GabyNg\n",
      "1278        6452      data-full/GabyNg/20190902_124535.mp4-1492.jpg   GabyNg\n",
      "1279        6454  data-full/LeeSeng/VID_20190905_204615.mp4-383.jpg  LeeSeng\n",
      "1280        6455            data-full/XiaoYan/IMG_4747.MOV-1073.jpg  XiaoYan\n",
      "\n",
      "[1281 rows x 3 columns]\n",
      "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator object at 0x7ff2d4f7e9e8>\n",
      "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator object at 0x7ff2d4f7ef60>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 43s 1s/step - loss: 0.5140 - acc: 0.9533 - val_loss: 294.8673 - val_acc: 0.3992\n",
      "Learning rate: 0.001\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 31s 892ms/step - loss: 0.2498 - acc: 0.9995 - val_loss: 17.0143 - val_acc: 0.6047\n",
      "Learning rate: 0.001\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 31s 898ms/step - loss: 0.2448 - acc: 1.0000 - val_loss: 2.2246 - val_acc: 0.7391\n",
      "Learning rate: 0.001\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 32s 904ms/step - loss: 0.2411 - acc: 1.0000 - val_loss: 0.4096 - val_acc: 0.9578\n",
      "Learning rate: 0.001\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 32s 909ms/step - loss: 0.2377 - acc: 0.9998 - val_loss: 0.2616 - val_acc: 0.9914\n",
      "Learning rate: 0.001\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 31s 881ms/step - loss: 0.2335 - acc: 1.0000 - val_loss: 0.2316 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 31s 895ms/step - loss: 0.2295 - acc: 1.0000 - val_loss: 0.2273 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 32s 904ms/step - loss: 0.2255 - acc: 1.0000 - val_loss: 0.2231 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 32s 921ms/step - loss: 0.2213 - acc: 1.0000 - val_loss: 0.2189 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 33s 934ms/step - loss: 0.2169 - acc: 1.0000 - val_loss: 0.2146 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 33s 953ms/step - loss: 0.2126 - acc: 1.0000 - val_loss: 0.2103 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 33s 933ms/step - loss: 0.2086 - acc: 1.0000 - val_loss: 0.2060 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 33s 935ms/step - loss: 0.2040 - acc: 1.0000 - val_loss: 0.2016 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 33s 936ms/step - loss: 0.1996 - acc: 1.0000 - val_loss: 0.1973 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 33s 950ms/step - loss: 0.1954 - acc: 1.0000 - val_loss: 0.1930 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 33s 936ms/step - loss: 0.1909 - acc: 1.0000 - val_loss: 0.1886 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 34s 966ms/step - loss: 0.1867 - acc: 1.0000 - val_loss: 0.1844 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 33s 937ms/step - loss: 0.1825 - acc: 1.0000 - val_loss: 0.1801 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 34s 973ms/step - loss: 0.1782 - acc: 1.0000 - val_loss: 0.1809 - val_acc: 0.9961\n",
      "Learning rate: 0.001\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 33s 944ms/step - loss: 0.1739 - acc: 1.0000 - val_loss: 0.1729 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 34s 960ms/step - loss: 0.1699 - acc: 1.0000 - val_loss: 0.1683 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 33s 940ms/step - loss: 0.1658 - acc: 1.0000 - val_loss: 0.1637 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 34s 960ms/step - loss: 0.1618 - acc: 1.0000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 33s 946ms/step - loss: 0.1578 - acc: 1.0000 - val_loss: 0.1558 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 33s 942ms/step - loss: 0.1539 - acc: 1.0000 - val_loss: 0.1520 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 33s 949ms/step - loss: 0.1501 - acc: 1.0000 - val_loss: 0.1481 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 34s 981ms/step - loss: 0.1464 - acc: 1.0000 - val_loss: 0.1444 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 33s 949ms/step - loss: 0.1428 - acc: 1.0000 - val_loss: 0.1411 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 34s 960ms/step - loss: 0.1392 - acc: 1.0000 - val_loss: 0.1373 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 33s 951ms/step - loss: 0.1356 - acc: 1.0000 - val_loss: 0.1338 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 34s 967ms/step - loss: 0.1498 - acc: 0.9940 - val_loss: 19.9978 - val_acc: 0.5875\n",
      "Learning rate: 0.001\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 34s 983ms/step - loss: 0.1554 - acc: 0.9937 - val_loss: 123.6890 - val_acc: 0.6289\n",
      "Learning rate: 0.001\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 34s 962ms/step - loss: 0.1375 - acc: 0.9982 - val_loss: 23.2005 - val_acc: 0.6883\n",
      "Learning rate: 0.001\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 34s 967ms/step - loss: 0.1305 - acc: 1.0000 - val_loss: 0.3079 - val_acc: 0.9734\n",
      "Learning rate: 0.001\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 33s 953ms/step - loss: 0.1555 - acc: 0.9924 - val_loss: 1.9552 - val_acc: 0.8188\n",
      "Learning rate: 0.001\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 34s 962ms/step - loss: 0.1332 - acc: 0.9979 - val_loss: 1.1736 - val_acc: 0.8734\n",
      "Learning rate: 0.001\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 28s 807ms/step - loss: 0.1240 - acc: 1.0000 - val_loss: 0.1407 - val_acc: 0.9930\n",
      "Learning rate: 0.001\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 31s 891ms/step - loss: 0.1212 - acc: 1.0000 - val_loss: 0.1202 - val_acc: 0.9992\n",
      "Learning rate: 0.001\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 31s 897ms/step - loss: 0.1184 - acc: 1.0000 - val_loss: 0.1170 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 31s 886ms/step - loss: 0.1174 - acc: 0.9991 - val_loss: 0.1142 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 32s 907ms/step - loss: 0.1132 - acc: 1.0000 - val_loss: 0.1116 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 31s 888ms/step - loss: 0.1104 - acc: 1.0000 - val_loss: 0.1090 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 31s 890ms/step - loss: 0.1091 - acc: 0.9995 - val_loss: 0.1065 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 32s 908ms/step - loss: 0.1061 - acc: 0.9993 - val_loss: 0.1041 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 32s 925ms/step - loss: 0.1033 - acc: 0.9998 - val_loss: 0.1017 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 32s 923ms/step - loss: 0.1012 - acc: 0.9995 - val_loss: 0.0995 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 33s 949ms/step - loss: 0.0985 - acc: 1.0000 - val_loss: 0.0971 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 33s 937ms/step - loss: 0.0961 - acc: 1.0000 - val_loss: 0.0948 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 33s 938ms/step - loss: 0.0942 - acc: 0.9998 - val_loss: 0.0927 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 33s 948ms/step - loss: 0.0917 - acc: 1.0000 - val_loss: 0.0905 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 33s 949ms/step - loss: 0.0899 - acc: 0.9998 - val_loss: 0.0886 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 33s 946ms/step - loss: 0.0905 - acc: 0.9984 - val_loss: 0.0888 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 34s 973ms/step - loss: 0.0868 - acc: 1.0000 - val_loss: 0.1247 - val_acc: 0.9883\n",
      "Learning rate: 0.001\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 33s 947ms/step - loss: 0.0853 - acc: 0.9995 - val_loss: 0.0832 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 33s 943ms/step - loss: 0.0824 - acc: 1.0000 - val_loss: 0.0812 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 34s 961ms/step - loss: 0.0805 - acc: 1.0000 - val_loss: 0.0793 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 33s 947ms/step - loss: 0.0785 - acc: 1.0000 - val_loss: 0.0775 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 33s 946ms/step - loss: 0.0767 - acc: 1.0000 - val_loss: 0.0757 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 34s 972ms/step - loss: 0.0748 - acc: 1.0000 - val_loss: 0.0739 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 33s 944ms/step - loss: 0.0733 - acc: 1.0000 - val_loss: 0.0722 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 33s 950ms/step - loss: 0.0715 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 33s 950ms/step - loss: 0.0697 - acc: 1.0000 - val_loss: 0.0689 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 34s 965ms/step - loss: 0.0681 - acc: 1.0000 - val_loss: 0.0673 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 33s 947ms/step - loss: 0.0665 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 34s 966ms/step - loss: 0.0653 - acc: 0.9998 - val_loss: 0.0643 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 34s 965ms/step - loss: 0.0660 - acc: 0.9991 - val_loss: 0.1090 - val_acc: 0.9844\n",
      "Learning rate: 0.001\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 33s 954ms/step - loss: 0.0644 - acc: 0.9998 - val_loss: 0.0629 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 34s 964ms/step - loss: 0.0634 - acc: 0.9995 - val_loss: 0.0614 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 34s 968ms/step - loss: 0.0611 - acc: 1.0000 - val_loss: 0.0642 - val_acc: 0.9984\n",
      "Learning rate: 0.001\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 34s 963ms/step - loss: 0.0595 - acc: 1.0000 - val_loss: 0.0586 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 34s 969ms/step - loss: 0.0902 - acc: 0.9954 - val_loss: 13.9444 - val_acc: 0.5977\n",
      "Learning rate: 0.001\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 34s 963ms/step - loss: 0.0742 - acc: 0.9963 - val_loss: 3.2305 - val_acc: 0.7422\n",
      "Learning rate: 0.001\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 28s 812ms/step - loss: 0.0652 - acc: 0.9989 - val_loss: 0.8890 - val_acc: 0.8547\n",
      "Learning rate: 0.001\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 31s 890ms/step - loss: 0.0637 - acc: 0.9986 - val_loss: 0.0799 - val_acc: 0.9945\n",
      "Learning rate: 0.001\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 31s 883ms/step - loss: 0.0632 - acc: 0.9993 - val_loss: 3.1144 - val_acc: 0.7672\n",
      "Learning rate: 0.001\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 31s 891ms/step - loss: 0.0614 - acc: 0.9986 - val_loss: 0.3427 - val_acc: 0.9641\n",
      "Learning rate: 0.001\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 31s 887ms/step - loss: 0.0675 - acc: 0.9982 - val_loss: 0.2321 - val_acc: 0.9742\n",
      "Learning rate: 0.001\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 31s 899ms/step - loss: 0.0618 - acc: 0.9989 - val_loss: 0.0716 - val_acc: 0.9953\n",
      "Learning rate: 0.001\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 31s 898ms/step - loss: 0.0559 - acc: 0.9995 - val_loss: 0.0552 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 32s 908ms/step - loss: 0.0544 - acc: 0.9998 - val_loss: 0.0531 - val_acc: 1.0000\n",
      "Learning rate: 0.001\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 32s 917ms/step - loss: 0.0533 - acc: 0.9995 - val_loss: 0.0942 - val_acc: 0.9859\n",
      "Learning rate: 0.0001\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 33s 939ms/step - loss: 0.0525 - acc: 0.9998 - val_loss: 0.0537 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 33s 956ms/step - loss: 0.0521 - acc: 1.0000 - val_loss: 0.0519 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 33s 954ms/step - loss: 0.0517 - acc: 1.0000 - val_loss: 0.0516 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 33s 950ms/step - loss: 0.0521 - acc: 0.9998 - val_loss: 0.0515 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 33s 941ms/step - loss: 0.0517 - acc: 1.0000 - val_loss: 0.0513 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 33s 940ms/step - loss: 0.0518 - acc: 0.9998 - val_loss: 0.0512 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 33s 951ms/step - loss: 0.0513 - acc: 1.0000 - val_loss: 0.0511 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 34s 973ms/step - loss: 0.0511 - acc: 1.0000 - val_loss: 0.0510 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 33s 953ms/step - loss: 0.0510 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 33s 937ms/step - loss: 0.0509 - acc: 1.0000 - val_loss: 0.0507 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 34s 959ms/step - loss: 0.0507 - acc: 1.0000 - val_loss: 0.0506 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 34s 957ms/step - loss: 0.0506 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 33s 941ms/step - loss: 0.0504 - acc: 1.0000 - val_loss: 0.0503 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 34s 975ms/step - loss: 0.0503 - acc: 1.0000 - val_loss: 0.0501 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 33s 943ms/step - loss: 0.0502 - acc: 1.0000 - val_loss: 0.0500 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 33s 949ms/step - loss: 0.0501 - acc: 1.0000 - val_loss: 0.0499 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 33s 952ms/step - loss: 0.0499 - acc: 1.0000 - val_loss: 0.0497 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 33s 949ms/step - loss: 0.0498 - acc: 1.0000 - val_loss: 0.0496 - val_acc: 1.0000\n",
      "Learning rate: 0.0001\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 34s 970ms/step - loss: 0.0495 - acc: 1.0000 - val_loss: 0.0494 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = createModel(target_size)\n",
    "print('model summary:', model.summary())\n",
    "\n",
    "filepath = modelname + \".hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=0,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "# Log the epoch detail into csv\n",
    "csv_logger = CSVLogger(modelname + '.csv')\n",
    "# callbacks_list  = [checkpoint,csv_logger]\n",
    "\n",
    "LRScheduler = LearningRateScheduler(lrSchedule)\n",
    "callbacks_list = [checkpoint, csv_logger, LRScheduler]\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.10,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "vdatagen = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    rotation_range=0,\n",
    "    zoom_range=0,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=tdf, x_col=\"filename\", y_col=\"label\",\n",
    "                                              class_mode=\"categorical\", target_size=target_size,\n",
    "                                              shuffle=True,\n",
    "                                              batch_size=batch_size)\n",
    "\n",
    "valid_generator = vdatagen.flow_from_dataframe(dataframe=vdf, x_col=\"filename\", y_col=\"label\",\n",
    "                                               class_mode=\"categorical\", target_size=target_size,\n",
    "                                               shuffle=True,\n",
    "                                               batch_size=batch_size)\n",
    "print(tdf)\n",
    "print(vdf)\n",
    "print(train_generator)\n",
    "print(valid_generator)\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    validation_data=valid_generator,\n",
    "                    epochs=epoch_size,\n",
    "                    verbose=1,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks=callbacks_list,\n",
    "                    workers=5,\n",
    "                    use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(modelname + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
